{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b3E14Z_e8ZTo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras import Sequential\n",
        "\n",
        "from mlxtend.plotting import plot_decision_regions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Peeking into Data\n",
        "\n",
        "df = pd.read_csv('/content/diabetes 2.csv')"
      ],
      "metadata": {
        "id": "VugFziQ-9THY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QmZeXYod9u-c",
        "outputId": "803017a6-6813-47d4-f6fa-99e08ec93c98"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5b74457-7adb-4be5-804e-adc2554a5520\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5b74457-7adb-4be5-804e-adc2554a5520')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5b74457-7adb-4be5-804e-adc2554a5520 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5b74457-7adb-4be5-804e-adc2554a5520');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb2ed415-9016-4a44-a7a6-6f82933e2bbf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb2ed415-9016-4a44-a7a6-6f82933e2bbf')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb2ed415-9016-4a44-a7a6-6f82933e2bbf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsBcP9QbU200",
        "outputId": "25dbed02-dda8-45a8-878b-f99aded0cc8f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Binary Classification Dataset to predict whether the person has diabilties or not"
      ],
      "metadata": {
        "id": "AwNQ7oP99yN6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking the Impact of each column on Outcome\n",
        "\n",
        "df.corr()['Outcome']*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3MY_v-R99tI",
        "outputId": "c35d6c37-1a74-4fd6-f422-98c70d0391d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                  22.189815\n",
              "Glucose                      46.658140\n",
              "BloodPressure                 6.506836\n",
              "SkinThickness                 7.475223\n",
              "Insulin                      13.054795\n",
              "BMI                          29.269466\n",
              "DiabetesPedigreeFunction     17.384407\n",
              "Age                          23.835598\n",
              "Outcome                     100.000000\n",
              "Name: Outcome, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking Missing and Zero Value\n",
        "\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpFrakmVRfRx",
        "outputId": "abfa05fc-2831-41c2-fb6f-667fcea3b835"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Checing Duplicate Row\n",
        "\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X8pzekkRfVT",
        "outputId": "d6ba684d-0275-48c1-98ae-45e758054f46"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking Zero Values\n",
        "\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "bDIqA1UoRfYg",
        "outputId": "b5d91d55-e5d8-4cf8-ed0b-149e9b49f3b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
              "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
              "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
              "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
              "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
              "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
              "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
              "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
              "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
              "\n",
              "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
              "count  768.000000                768.000000  768.000000  768.000000  \n",
              "mean    31.992578                  0.471876   33.240885    0.348958  \n",
              "std      7.884160                  0.331329   11.760232    0.476951  \n",
              "min      0.000000                  0.078000   21.000000    0.000000  \n",
              "25%     27.300000                  0.243750   24.000000    0.000000  \n",
              "50%     32.000000                  0.372500   29.000000    0.000000  \n",
              "75%     36.600000                  0.626250   41.000000    1.000000  \n",
              "max     67.100000                  2.420000   81.000000    1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b914c1ca-493a-4d98-84be-b94153b1fd58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b914c1ca-493a-4d98-84be-b94153b1fd58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b914c1ca-493a-4d98-84be-b94153b1fd58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b914c1ca-493a-4d98-84be-b94153b1fd58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1da225bc-bef4-44be-9d20-8245d06a085f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1da225bc-bef4-44be-9d20-8245d06a085f')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1da225bc-bef4-44be-9d20-8245d06a085f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every column has 0 as min value attached to it and its not possible for few of them"
      ],
      "metadata": {
        "id": "ME8wAHxETE9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking No. of Zeros in each Column\n",
        "\n",
        "for i in (df.columns):\n",
        "  print(i , (df[i]==0).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmP6jJMNR8y5",
        "outputId": "1ecfe076-d57d-4cbf-f284-6f0069a78eb9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregnancies 111\n",
            "Glucose 5\n",
            "BloodPressure 35\n",
            "SkinThickness 227\n",
            "Insulin 374\n",
            "BMI 11\n",
            "DiabetesPedigreeFunction 0\n",
            "Age 0\n",
            "Outcome 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Extracting parameters\n",
        "\n",
        "x = df.iloc[:, :-1]\n",
        "y  = df.iloc[:,-1]"
      ],
      "metadata": {
        "id": "455AhsTw-VNN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Filling Zero Values\n",
        "\n",
        "for i in x:\n",
        "  x[i]= np.where(x[i]==0, x[i].mean(),x[i])"
      ],
      "metadata": {
        "id": "cFxTnm4aWKh8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "RagblghQZpce",
        "outputId": "cc6ec1b5-5781-450a-a7bc-a9a38aa96782"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
              "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
              "mean      4.400782  121.681605      72.254807      26.606479  118.660163   \n",
              "std       2.984162   30.436016      12.115932       9.631241   93.080358   \n",
              "min       1.000000   44.000000      24.000000       7.000000   14.000000   \n",
              "25%       2.000000   99.750000      64.000000      20.536458   79.799479   \n",
              "50%       3.845052  117.000000      72.000000      23.000000   79.799479   \n",
              "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
              "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
              "\n",
              "              BMI  DiabetesPedigreeFunction         Age  \n",
              "count  768.000000                768.000000  768.000000  \n",
              "mean    32.450805                  0.471876   33.240885  \n",
              "std      6.875374                  0.331329   11.760232  \n",
              "min     18.200000                  0.078000   21.000000  \n",
              "25%     27.500000                  0.243750   24.000000  \n",
              "50%     32.000000                  0.372500   29.000000  \n",
              "75%     36.600000                  0.626250   41.000000  \n",
              "max     67.100000                  2.420000   81.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ce07e23-16e3-42f0-b552-3832f6d1a165\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.400782</td>\n",
              "      <td>121.681605</td>\n",
              "      <td>72.254807</td>\n",
              "      <td>26.606479</td>\n",
              "      <td>118.660163</td>\n",
              "      <td>32.450805</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.984162</td>\n",
              "      <td>30.436016</td>\n",
              "      <td>12.115932</td>\n",
              "      <td>9.631241</td>\n",
              "      <td>93.080358</td>\n",
              "      <td>6.875374</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>18.200000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>99.750000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>27.500000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ce07e23-16e3-42f0-b552-3832f6d1a165')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ce07e23-16e3-42f0-b552-3832f6d1a165 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ce07e23-16e3-42f0-b552-3832f6d1a165');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0742598b-a551-4fc7-b279-e44c9879ac19\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0742598b-a551-4fc7-b279-e44c9879ac19')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0742598b-a551-4fc7-b279-e44c9879ac19 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimum Value is Non-Zero Now"
      ],
      "metadata": {
        "id": "ltTFSulTZ8Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Splitng the data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train,y_test = train_test_split(x, y, test_size=0.2, random_state = 1)"
      ],
      "metadata": {
        "id": "Ye7BgLX3-9zh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Feature Scaling\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "x_train = ss.fit_transform(x_train)\n",
        "x_test = ss.transform(x_test)"
      ],
      "metadata": {
        "id": "8kwkAiBtaMJw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Building Normal ANN\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation = 'relu', input_dim=8))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "history = model.fit(x_train, y_train , batch_size=32, epochs = 100,validation_data = (x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98R3rzlW_SP4",
        "outputId": "d14604f6-8103-4b66-b5ac-40b74f132627"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 15ms/step - loss: 0.7136 - accuracy: 0.4870 - val_loss: 0.6633 - val_accuracy: 0.6558\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6596 - val_loss: 0.5985 - val_accuracy: 0.7338\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.6987 - val_loss: 0.5552 - val_accuracy: 0.7662\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7280 - val_loss: 0.5228 - val_accuracy: 0.7792\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7378 - val_loss: 0.5003 - val_accuracy: 0.7727\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7476 - val_loss: 0.4835 - val_accuracy: 0.7727\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7557 - val_loss: 0.4726 - val_accuracy: 0.7727\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4907 - accuracy: 0.7622 - val_loss: 0.4638 - val_accuracy: 0.7792\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7687 - val_loss: 0.4562 - val_accuracy: 0.7792\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7720 - val_loss: 0.4499 - val_accuracy: 0.7857\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7736 - val_loss: 0.4457 - val_accuracy: 0.7792\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7785 - val_loss: 0.4432 - val_accuracy: 0.7857\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7785 - val_loss: 0.4392 - val_accuracy: 0.7922\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7801 - val_loss: 0.4350 - val_accuracy: 0.7922\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7785 - val_loss: 0.4325 - val_accuracy: 0.7922\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7866 - val_loss: 0.4307 - val_accuracy: 0.7987\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7834 - val_loss: 0.4285 - val_accuracy: 0.7987\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7818 - val_loss: 0.4272 - val_accuracy: 0.8117\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7850 - val_loss: 0.4258 - val_accuracy: 0.8052\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7850 - val_loss: 0.4239 - val_accuracy: 0.8052\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7899 - val_loss: 0.4237 - val_accuracy: 0.8117\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7866 - val_loss: 0.4232 - val_accuracy: 0.8052\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7899 - val_loss: 0.4221 - val_accuracy: 0.8052\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7883 - val_loss: 0.4217 - val_accuracy: 0.8052\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7899 - val_loss: 0.4203 - val_accuracy: 0.8052\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7883 - val_loss: 0.4200 - val_accuracy: 0.7987\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7866 - val_loss: 0.4198 - val_accuracy: 0.7987\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7883 - val_loss: 0.4189 - val_accuracy: 0.7987\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7866 - val_loss: 0.4183 - val_accuracy: 0.8117\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7899 - val_loss: 0.4180 - val_accuracy: 0.8117\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7883 - val_loss: 0.4173 - val_accuracy: 0.7987\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7866 - val_loss: 0.4175 - val_accuracy: 0.8052\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7866 - val_loss: 0.4164 - val_accuracy: 0.8182\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7899 - val_loss: 0.4171 - val_accuracy: 0.8117\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7866 - val_loss: 0.4166 - val_accuracy: 0.8182\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7883 - val_loss: 0.4167 - val_accuracy: 0.8117\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7899 - val_loss: 0.4166 - val_accuracy: 0.8052\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7883 - val_loss: 0.4163 - val_accuracy: 0.8117\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7866 - val_loss: 0.4157 - val_accuracy: 0.8117\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7866 - val_loss: 0.4156 - val_accuracy: 0.8117\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7883 - val_loss: 0.4153 - val_accuracy: 0.8182\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.4147 - val_accuracy: 0.8117\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7899 - val_loss: 0.4143 - val_accuracy: 0.8182\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7866 - val_loss: 0.4145 - val_accuracy: 0.8182\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7915 - val_loss: 0.4144 - val_accuracy: 0.8052\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7899 - val_loss: 0.4149 - val_accuracy: 0.8182\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7915 - val_loss: 0.4148 - val_accuracy: 0.8182\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7948 - val_loss: 0.4148 - val_accuracy: 0.8182\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7932 - val_loss: 0.4143 - val_accuracy: 0.8182\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7915 - val_loss: 0.4138 - val_accuracy: 0.8117\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7932 - val_loss: 0.4136 - val_accuracy: 0.8117\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.4130 - val_accuracy: 0.8117\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7980 - val_loss: 0.4134 - val_accuracy: 0.8117\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7997 - val_loss: 0.4146 - val_accuracy: 0.8117\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7932 - val_loss: 0.4134 - val_accuracy: 0.8052\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7932 - val_loss: 0.4130 - val_accuracy: 0.7987\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7964 - val_loss: 0.4133 - val_accuracy: 0.7987\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7932 - val_loss: 0.4140 - val_accuracy: 0.7987\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7932 - val_loss: 0.4130 - val_accuracy: 0.7922\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.7964 - val_loss: 0.4129 - val_accuracy: 0.7987\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.7899 - val_loss: 0.4109 - val_accuracy: 0.7987\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7980 - val_loss: 0.4121 - val_accuracy: 0.7922\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7932 - val_loss: 0.4121 - val_accuracy: 0.7922\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.4121 - val_accuracy: 0.7922\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7834 - val_loss: 0.4135 - val_accuracy: 0.7922\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.7866 - val_loss: 0.4136 - val_accuracy: 0.7922\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7915 - val_loss: 0.4130 - val_accuracy: 0.7922\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4188 - accuracy: 0.7932 - val_loss: 0.4138 - val_accuracy: 0.7922\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.7932 - val_loss: 0.4133 - val_accuracy: 0.7922\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7899 - val_loss: 0.4135 - val_accuracy: 0.7922\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.7964 - val_loss: 0.4139 - val_accuracy: 0.7922\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.7948 - val_loss: 0.4130 - val_accuracy: 0.7987\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.7883 - val_loss: 0.4127 - val_accuracy: 0.7922\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.7948 - val_loss: 0.4129 - val_accuracy: 0.7922\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.7948 - val_loss: 0.4129 - val_accuracy: 0.7922\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.7932 - val_loss: 0.4134 - val_accuracy: 0.7922\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.7948 - val_loss: 0.4139 - val_accuracy: 0.7922\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.7997 - val_loss: 0.4132 - val_accuracy: 0.7922\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4150 - accuracy: 0.7948 - val_loss: 0.4128 - val_accuracy: 0.7987\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.7915 - val_loss: 0.4127 - val_accuracy: 0.7987\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.7980 - val_loss: 0.4142 - val_accuracy: 0.7987\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.7997 - val_loss: 0.4148 - val_accuracy: 0.7987\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.7997 - val_loss: 0.4152 - val_accuracy: 0.7987\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.7980 - val_loss: 0.4147 - val_accuracy: 0.7987\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.7964 - val_loss: 0.4150 - val_accuracy: 0.7987\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.7980 - val_loss: 0.4155 - val_accuracy: 0.7987\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.7932 - val_loss: 0.4151 - val_accuracy: 0.7987\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.7915 - val_loss: 0.4166 - val_accuracy: 0.7987\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.7980 - val_loss: 0.4168 - val_accuracy: 0.7987\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.7980 - val_loss: 0.4162 - val_accuracy: 0.7987\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.7964 - val_loss: 0.4165 - val_accuracy: 0.7987\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.7980 - val_loss: 0.4145 - val_accuracy: 0.7987\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.7980 - val_loss: 0.4155 - val_accuracy: 0.7987\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.7980 - val_loss: 0.4160 - val_accuracy: 0.7987\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8013 - val_loss: 0.4145 - val_accuracy: 0.7987\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.7997 - val_loss: 0.4163 - val_accuracy: 0.7987\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8046 - val_loss: 0.4157 - val_accuracy: 0.7987\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8013 - val_loss: 0.4165 - val_accuracy: 0.7987\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8029 - val_loss: 0.4155 - val_accuracy: 0.7987\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8029 - val_loss: 0.4164 - val_accuracy: 0.7987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Val_Accuracy = 79.87"
      ],
      "metadata": {
        "id": "i9KUfsqNagWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter Tunning"
      ],
      "metadata": {
        "id": "a5iN2Dx5akHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## The problem is while building the model we are clueless in terms of deciding\n",
        "## >> No. of Hidden Layer\n",
        "## >> No. of Neurons in each hidden layer\n",
        "## >> Which activaiton function to use\n",
        "## >> which optimizer to use\n",
        "## >> How many epochs we need to give\n",
        "\n",
        "## To automate this use Hyperparameter Tunning using the library knows as keras-tuner\n",
        "## Aim to find the best suitable parameters for our model.\n",
        "\n",
        "## We will follow this step by step and then collate the output\n",
        "\n",
        "## Step1: How to select appropriate optimizer\n",
        "## Step2: How to select no. of neurons in a layer\n",
        "## Step3: How to selection no. of hidden layers\n",
        "## Finally we wil combine"
      ],
      "metadata": {
        "id": "thhcwsooAZQt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Insalling Keras tunner\n",
        "\n",
        "!pip install -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZcuChvsB2Cr",
        "outputId": "74ed1051-7ae7-47b6-af12-ed065b8e5cfa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.5-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m129.5/129.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-core (from keras-tuner)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (1.23.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (13.6.0)\n",
            "Collecting namex (from keras-core->keras-tuner)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (0.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner) (0.1.2)\n",
            "Installing collected packages: namex, kt-legacy, keras-core, keras-tuner\n",
            "Successfully installed keras-core-0.1.7 keras-tuner-1.4.5 kt-legacy-1.0.5 namex-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 1 :  Selectiing the Apprpriate Optimizer\n",
        "\n",
        "## Three Steps to follow\n",
        "## Step 1: We first create a function\n",
        "## Step 2: Create a tuner object\n",
        "## Step 3: We pass this function to that tunner object\n",
        "\n",
        "import keras_tuner as kt\n",
        "\n",
        "# Step 1 : Building the Function\n",
        "\n",
        "def build_model1(hp):  ## hp = hyperparameter object\n",
        "\n",
        "  ## We will start building our model from scrach\n",
        "  ## To give the model choice to choose optimizer, we use the function,. hp.Choice(<name>, values =[])\n",
        "\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32, activation = 'relu', input_dim = 8))\n",
        "  model.add(Dense(1, activation = 'sigmoid'))\n",
        "  opt = hp.Choice('Optimizer', values = ['adam', 'SGD', 'rmsprop','adadelta', 'nadam'])\n",
        "  model.compile(optimizer = opt , loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "rdyKL7EGCugB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2 : Creating a tunner object\n",
        "\n",
        "## To create the object we use the keras-tuner.RandomSeach() fucntion , where we define the 5 arguments\n",
        "## <fucntion_name> = Fuction we created in Step1\n",
        "## <max_trials> = Total No. of Trials to Test, Default Value = 10\n",
        "## <Objection> = Quantity on which we want to focus on like val_accuracy, val_loss\n",
        "## <directory> = Once we run the tunner it create a directory , this paramert is to give name to tha directory\n",
        "## <project_name> = The result of each trial will be save in a new folder, we this is to give name to that project\n",
        "\n",
        "tuner = kt.RandomSearch(build_model1,\n",
        "                        objective='val_accuracy',\n",
        "                        max_trials=5,\n",
        "                        directory = 'mydir',\n",
        "                        project_name = 'Optimizer_Tunning')\n"
      ],
      "metadata": {
        "id": "wHc6Mi4hEtgS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3: Passing the Data to the tunner\n",
        "## Now the tunner object has been create we have pass the data to it to execute the trial to finds the best optimizer\n",
        "## Its like training the model.\n",
        "## For passing the data. we use tuner.search(training data, epcchs, validation_data)\n",
        "\n",
        "tuner.search(x_train, y_train, epochs =5 , validation_data = (x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlo73ktuFKyE",
        "outputId": "c80be02b-b8fe-4a67-c3ac-5b3c9fc885ee"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 02s]\n",
            "val_accuracy: 0.7142857313156128\n",
            "\n",
            "Best val_accuracy So Far: 0.7922077775001526\n",
            "Total elapsed time: 00h 00m 11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking the Best Parametes\n",
        "## TO check the best parameters, we use, tuner.get_best_hyperparameters()[0].values\n",
        "\n",
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWbxW2wDF9Vh",
        "outputId": "ef05cb4d-47a2-4ccb-e345-26c77461d56d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Optimizer': 'adam'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is is giving is parameter as nadam"
      ],
      "metadata": {
        "id": "im12G4V8fZ1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a new Model with Tunner Results\n",
        "## There are 2 ways, either we explicity create a new model and then add 'nadam' as optimizer to it or we pass create the model\n",
        "## using tunner result implicitly\n",
        "## Here we will focus in creating the Model using Tunner result implicitly\n",
        "## For this we will us  tunner.get_best_models(num_model=1)[0]\n",
        "\n",
        "\n",
        "model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "xBoamCYdGXS_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking the architecture\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQHhmGEeGl7c",
        "outputId": "f2e4e4c0-0aa1-4830-925b-45222078db7a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32)                288       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321 (1.25 KB)\n",
            "Trainable params: 321 (1.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Fitting the Model with the tunner results with an addtion of initial_epoch parameter, since tunner already done with 5 epochs\n",
        "## so we want to start from the end result so we will give the inital_epoch as 6, with same batch size=32\n",
        "\n",
        "model.fit(x_train, y_train, batch_size = 32, epochs=100, initial_epoch=6, validation_data = (x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKuB4lJvGngz",
        "outputId": "3914cf38-94bf-45f3-d8a5-e43345cd8bdd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100\n",
            "20/20 [==============================] - 1s 13ms/step - loss: 0.5126 - accuracy: 0.7427 - val_loss: 0.4996 - val_accuracy: 0.7987\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7557 - val_loss: 0.4858 - val_accuracy: 0.8117\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7622 - val_loss: 0.4762 - val_accuracy: 0.8117\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7687 - val_loss: 0.4677 - val_accuracy: 0.7987\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7769 - val_loss: 0.4619 - val_accuracy: 0.7987\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7785 - val_loss: 0.4559 - val_accuracy: 0.7987\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7785 - val_loss: 0.4527 - val_accuracy: 0.7857\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7785 - val_loss: 0.4502 - val_accuracy: 0.7857\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7818 - val_loss: 0.4468 - val_accuracy: 0.7857\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7818 - val_loss: 0.4449 - val_accuracy: 0.7922\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7834 - val_loss: 0.4428 - val_accuracy: 0.7857\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7769 - val_loss: 0.4405 - val_accuracy: 0.7792\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7769 - val_loss: 0.4401 - val_accuracy: 0.7857\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7752 - val_loss: 0.4388 - val_accuracy: 0.7727\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7720 - val_loss: 0.4373 - val_accuracy: 0.7857\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7704 - val_loss: 0.4376 - val_accuracy: 0.7727\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7704 - val_loss: 0.4371 - val_accuracy: 0.7727\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7687 - val_loss: 0.4361 - val_accuracy: 0.7727\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7704 - val_loss: 0.4350 - val_accuracy: 0.7792\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7704 - val_loss: 0.4344 - val_accuracy: 0.7792\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7720 - val_loss: 0.4335 - val_accuracy: 0.7792\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7704 - val_loss: 0.4334 - val_accuracy: 0.7857\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7736 - val_loss: 0.4333 - val_accuracy: 0.7857\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.7736 - val_loss: 0.4318 - val_accuracy: 0.7857\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.7752 - val_loss: 0.4315 - val_accuracy: 0.7857\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7752 - val_loss: 0.4314 - val_accuracy: 0.7857\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7752 - val_loss: 0.4310 - val_accuracy: 0.7857\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.7801 - val_loss: 0.4299 - val_accuracy: 0.7857\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4347 - accuracy: 0.7785 - val_loss: 0.4303 - val_accuracy: 0.7857\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.7785 - val_loss: 0.4299 - val_accuracy: 0.7922\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4332 - accuracy: 0.7801 - val_loss: 0.4294 - val_accuracy: 0.7922\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.7818 - val_loss: 0.4296 - val_accuracy: 0.7922\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.7866 - val_loss: 0.4286 - val_accuracy: 0.7922\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.7850 - val_loss: 0.4296 - val_accuracy: 0.7857\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4309 - accuracy: 0.7883 - val_loss: 0.4293 - val_accuracy: 0.7922\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.4293 - val_accuracy: 0.7857\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.7915 - val_loss: 0.4301 - val_accuracy: 0.7922\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.7883 - val_loss: 0.4304 - val_accuracy: 0.7922\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.7883 - val_loss: 0.4300 - val_accuracy: 0.7922\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4283 - accuracy: 0.7866 - val_loss: 0.4282 - val_accuracy: 0.7922\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.7866 - val_loss: 0.4274 - val_accuracy: 0.7922\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.7818 - val_loss: 0.4280 - val_accuracy: 0.7922\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.7834 - val_loss: 0.4276 - val_accuracy: 0.7922\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.7883 - val_loss: 0.4278 - val_accuracy: 0.7922\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.7850 - val_loss: 0.4269 - val_accuracy: 0.7922\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4245 - accuracy: 0.7834 - val_loss: 0.4271 - val_accuracy: 0.7922\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.7866 - val_loss: 0.4271 - val_accuracy: 0.7922\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.7866 - val_loss: 0.4275 - val_accuracy: 0.7922\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4234 - accuracy: 0.7866 - val_loss: 0.4275 - val_accuracy: 0.7922\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.7866 - val_loss: 0.4271 - val_accuracy: 0.7857\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.7850 - val_loss: 0.4262 - val_accuracy: 0.7857\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.7850 - val_loss: 0.4260 - val_accuracy: 0.7922\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7850 - val_loss: 0.4263 - val_accuracy: 0.7857\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7850 - val_loss: 0.4264 - val_accuracy: 0.7857\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7866 - val_loss: 0.4261 - val_accuracy: 0.7792\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7883 - val_loss: 0.4260 - val_accuracy: 0.7857\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7866 - val_loss: 0.4259 - val_accuracy: 0.7857\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7866 - val_loss: 0.4252 - val_accuracy: 0.7857\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7899 - val_loss: 0.4250 - val_accuracy: 0.7857\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7915 - val_loss: 0.4244 - val_accuracy: 0.7857\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7883 - val_loss: 0.4250 - val_accuracy: 0.7792\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.7899 - val_loss: 0.4247 - val_accuracy: 0.7792\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.7915 - val_loss: 0.4249 - val_accuracy: 0.7857\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.7915 - val_loss: 0.4249 - val_accuracy: 0.7792\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.7915 - val_loss: 0.4248 - val_accuracy: 0.7857\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.7883 - val_loss: 0.4242 - val_accuracy: 0.7857\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7915 - val_loss: 0.4243 - val_accuracy: 0.7792\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.7899 - val_loss: 0.4247 - val_accuracy: 0.7857\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.7899 - val_loss: 0.4238 - val_accuracy: 0.7857\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.7915 - val_loss: 0.4235 - val_accuracy: 0.7857\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.7915 - val_loss: 0.4236 - val_accuracy: 0.7922\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.7899 - val_loss: 0.4231 - val_accuracy: 0.7922\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.7932 - val_loss: 0.4231 - val_accuracy: 0.7857\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.7948 - val_loss: 0.4226 - val_accuracy: 0.7792\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.7915 - val_loss: 0.4218 - val_accuracy: 0.7922\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.7948 - val_loss: 0.4230 - val_accuracy: 0.7857\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.4120 - accuracy: 0.7932 - val_loss: 0.4239 - val_accuracy: 0.7922\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4121 - accuracy: 0.7964 - val_loss: 0.4223 - val_accuracy: 0.7922\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.7948 - val_loss: 0.4215 - val_accuracy: 0.7922\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.7948 - val_loss: 0.4208 - val_accuracy: 0.7922\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.7948 - val_loss: 0.4208 - val_accuracy: 0.7857\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.7932 - val_loss: 0.4219 - val_accuracy: 0.7922\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.7932 - val_loss: 0.4224 - val_accuracy: 0.7987\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.7948 - val_loss: 0.4222 - val_accuracy: 0.7922\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.7915 - val_loss: 0.4216 - val_accuracy: 0.7987\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7948 - val_loss: 0.4217 - val_accuracy: 0.7987\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.7915 - val_loss: 0.4212 - val_accuracy: 0.7987\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.7932 - val_loss: 0.4212 - val_accuracy: 0.7987\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7932 - val_loss: 0.4214 - val_accuracy: 0.7987\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.7948 - val_loss: 0.4211 - val_accuracy: 0.7857\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.7932 - val_loss: 0.4204 - val_accuracy: 0.7857\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.7964 - val_loss: 0.4209 - val_accuracy: 0.7922\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.7948 - val_loss: 0.4216 - val_accuracy: 0.7922\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.7964 - val_loss: 0.4222 - val_accuracy: 0.7922\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ac92a11a290>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Val_accuracy = 79.22% , May requite more epochs"
      ],
      "metadata": {
        "id": "ihg8HqxUhwJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. No. of Neurons in layer using Hyper Parameter Tunning\n",
        "\n",
        "\n",
        "## Step 1 :  Building the Funcitons\n",
        "## For tunning the No.of neurons, we use function as .Int(<name>, start, stop, step)\n",
        "\n",
        "\n",
        "def build_model2(hp1):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  unit = hp1.Int('Neuron', 8,128,8)\n",
        "\n",
        "  model.add(Dense(unit, activation='relu', input_dim =8))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "bP660OkuHAMQ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2 :  Creating the Tunner Object\n",
        "\n",
        "tuner1 = kt.RandomSearch(build_model2,\n",
        "                         objective = 'val_accuracy',\n",
        "                         max_trials=5,\n",
        "                         directory = 'mydir',\n",
        "                         project_name = 'Neuron_Hypertunning'\n",
        "                        )"
      ],
      "metadata": {
        "id": "ZwW4g--6IGmr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3: Pass Data to the tunner\n",
        "\n",
        "tuner1.search(x_train,y_train, epochs = 5, validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ds6Y9QiIbkh",
        "outputId": "43758b3e-4fb9-4b50-ee31-6cdf9945f7ae"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 02s]\n",
            "val_accuracy: 0.5714285969734192\n",
            "\n",
            "Best val_accuracy So Far: 0.8116883039474487\n",
            "Total elapsed time: 00h 00m 11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking the Best Parameters\n",
        "\n",
        "tuner1.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0jNkylxI0gN",
        "outputId": "4b792b11-c43d-40e0-90d1-1c5704ab4027"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Neuron': 128}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Fitting the Model with tunner result and fitting the same\n",
        "\n",
        "\n",
        "model1 = tuner1.get_best_models(num_models=1)[0]\n",
        "model1.fit(x_train, y_train, epochs=200, initial_epoch = 5,batch_size =32,  validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkbL6GGpKAYO",
        "outputId": "12e5031f-6d75-47b9-8194-9a657e636a59"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/200\n",
            "20/20 [==============================] - 2s 19ms/step - loss: 0.4725 - accuracy: 0.7687 - val_loss: 0.4436 - val_accuracy: 0.7922\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7752 - val_loss: 0.4374 - val_accuracy: 0.8052\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7818 - val_loss: 0.4335 - val_accuracy: 0.7987\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4540 - accuracy: 0.7834 - val_loss: 0.4309 - val_accuracy: 0.8052\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7818 - val_loss: 0.4288 - val_accuracy: 0.7922\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7866 - val_loss: 0.4275 - val_accuracy: 0.7987\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7834 - val_loss: 0.4239 - val_accuracy: 0.7987\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4419 - accuracy: 0.7801 - val_loss: 0.4220 - val_accuracy: 0.7987\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.7818 - val_loss: 0.4220 - val_accuracy: 0.7987\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4387 - accuracy: 0.7769 - val_loss: 0.4217 - val_accuracy: 0.8052\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7785 - val_loss: 0.4202 - val_accuracy: 0.8052\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7769 - val_loss: 0.4198 - val_accuracy: 0.8117\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7801 - val_loss: 0.4188 - val_accuracy: 0.8117\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7818 - val_loss: 0.4199 - val_accuracy: 0.8052\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7801 - val_loss: 0.4184 - val_accuracy: 0.7987\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7834 - val_loss: 0.4204 - val_accuracy: 0.7987\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7834 - val_loss: 0.4195 - val_accuracy: 0.8117\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7834 - val_loss: 0.4202 - val_accuracy: 0.8052\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7850 - val_loss: 0.4189 - val_accuracy: 0.7987\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7818 - val_loss: 0.4184 - val_accuracy: 0.7922\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7915 - val_loss: 0.4174 - val_accuracy: 0.7987\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7932 - val_loss: 0.4178 - val_accuracy: 0.7922\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7915 - val_loss: 0.4175 - val_accuracy: 0.7987\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7932 - val_loss: 0.4164 - val_accuracy: 0.7987\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7899 - val_loss: 0.4161 - val_accuracy: 0.7987\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.7899 - val_loss: 0.4161 - val_accuracy: 0.7987\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.7850 - val_loss: 0.4156 - val_accuracy: 0.7987\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.7915 - val_loss: 0.4157 - val_accuracy: 0.7987\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.7866 - val_loss: 0.4156 - val_accuracy: 0.8052\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.7883 - val_loss: 0.4162 - val_accuracy: 0.7987\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.7866 - val_loss: 0.4152 - val_accuracy: 0.8117\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.7932 - val_loss: 0.4160 - val_accuracy: 0.7922\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.7899 - val_loss: 0.4178 - val_accuracy: 0.7987\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.7980 - val_loss: 0.4176 - val_accuracy: 0.8117\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.7964 - val_loss: 0.4170 - val_accuracy: 0.8052\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.7932 - val_loss: 0.4171 - val_accuracy: 0.8182\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.7915 - val_loss: 0.4157 - val_accuracy: 0.8117\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.7964 - val_loss: 0.4151 - val_accuracy: 0.8117\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.7980 - val_loss: 0.4162 - val_accuracy: 0.8117\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.7915 - val_loss: 0.4165 - val_accuracy: 0.8117\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.7932 - val_loss: 0.4163 - val_accuracy: 0.8052\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.7932 - val_loss: 0.4171 - val_accuracy: 0.7987\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8029 - val_loss: 0.4190 - val_accuracy: 0.8117\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.7980 - val_loss: 0.4210 - val_accuracy: 0.8247\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.7980 - val_loss: 0.4190 - val_accuracy: 0.8117\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.7980 - val_loss: 0.4182 - val_accuracy: 0.8117\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.7964 - val_loss: 0.4168 - val_accuracy: 0.7922\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8013 - val_loss: 0.4170 - val_accuracy: 0.8117\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.7964 - val_loss: 0.4150 - val_accuracy: 0.7922\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8029 - val_loss: 0.4182 - val_accuracy: 0.8117\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8062 - val_loss: 0.4181 - val_accuracy: 0.8247\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.7997 - val_loss: 0.4180 - val_accuracy: 0.7922\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8062 - val_loss: 0.4204 - val_accuracy: 0.8117\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8062 - val_loss: 0.4175 - val_accuracy: 0.8117\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8046 - val_loss: 0.4166 - val_accuracy: 0.8117\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8013 - val_loss: 0.4144 - val_accuracy: 0.8182\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.7997 - val_loss: 0.4158 - val_accuracy: 0.7857\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.7948 - val_loss: 0.4177 - val_accuracy: 0.8117\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8029 - val_loss: 0.4178 - val_accuracy: 0.8247\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8094 - val_loss: 0.4179 - val_accuracy: 0.8117\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8094 - val_loss: 0.4185 - val_accuracy: 0.8117\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8062 - val_loss: 0.4161 - val_accuracy: 0.8182\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 0.3901 - accuracy: 0.8062 - val_loss: 0.4165 - val_accuracy: 0.8052\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 0.3899 - accuracy: 0.8062 - val_loss: 0.4169 - val_accuracy: 0.8052\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.3888 - accuracy: 0.8062 - val_loss: 0.4180 - val_accuracy: 0.8052\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.3887 - accuracy: 0.8046 - val_loss: 0.4169 - val_accuracy: 0.8052\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.8078 - val_loss: 0.4162 - val_accuracy: 0.8117\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.8062 - val_loss: 0.4194 - val_accuracy: 0.8052\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.8111 - val_loss: 0.4194 - val_accuracy: 0.8117\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8062 - val_loss: 0.4181 - val_accuracy: 0.8117\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8029 - val_loss: 0.4171 - val_accuracy: 0.8052\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8029 - val_loss: 0.4152 - val_accuracy: 0.7987\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.8127 - val_loss: 0.4194 - val_accuracy: 0.7987\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8127 - val_loss: 0.4198 - val_accuracy: 0.8052\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8143 - val_loss: 0.4184 - val_accuracy: 0.7922\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8062 - val_loss: 0.4198 - val_accuracy: 0.8052\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8094 - val_loss: 0.4194 - val_accuracy: 0.8052\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.8111 - val_loss: 0.4214 - val_accuracy: 0.7987\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8127 - val_loss: 0.4205 - val_accuracy: 0.7987\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8094 - val_loss: 0.4206 - val_accuracy: 0.7987\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8127 - val_loss: 0.4199 - val_accuracy: 0.7922\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3793 - accuracy: 0.8127 - val_loss: 0.4197 - val_accuracy: 0.8052\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8176 - val_loss: 0.4194 - val_accuracy: 0.8117\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.8192 - val_loss: 0.4196 - val_accuracy: 0.8117\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3774 - accuracy: 0.8208 - val_loss: 0.4173 - val_accuracy: 0.8052\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3778 - accuracy: 0.8143 - val_loss: 0.4177 - val_accuracy: 0.8052\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.8143 - val_loss: 0.4203 - val_accuracy: 0.8052\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8192 - val_loss: 0.4198 - val_accuracy: 0.8052\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3750 - accuracy: 0.8225 - val_loss: 0.4225 - val_accuracy: 0.8117\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8192 - val_loss: 0.4213 - val_accuracy: 0.8052\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.8176 - val_loss: 0.4226 - val_accuracy: 0.8052\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8192 - val_loss: 0.4212 - val_accuracy: 0.8052\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8274 - val_loss: 0.4233 - val_accuracy: 0.8052\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8339 - val_loss: 0.4224 - val_accuracy: 0.8052\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8241 - val_loss: 0.4226 - val_accuracy: 0.8052\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8257 - val_loss: 0.4242 - val_accuracy: 0.8052\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8257 - val_loss: 0.4236 - val_accuracy: 0.8052\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.8208 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8241 - val_loss: 0.4231 - val_accuracy: 0.8052\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8225 - val_loss: 0.4241 - val_accuracy: 0.8052\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8241 - val_loss: 0.4224 - val_accuracy: 0.7987\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3694 - accuracy: 0.8257 - val_loss: 0.4230 - val_accuracy: 0.8052\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8274 - val_loss: 0.4210 - val_accuracy: 0.7987\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8274 - val_loss: 0.4229 - val_accuracy: 0.7987\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3667 - accuracy: 0.8339 - val_loss: 0.4246 - val_accuracy: 0.7987\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3652 - accuracy: 0.8241 - val_loss: 0.4220 - val_accuracy: 0.7987\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8274 - val_loss: 0.4239 - val_accuracy: 0.7987\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8339 - val_loss: 0.4247 - val_accuracy: 0.7987\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.8388 - val_loss: 0.4290 - val_accuracy: 0.7987\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8371 - val_loss: 0.4296 - val_accuracy: 0.7987\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8306 - val_loss: 0.4259 - val_accuracy: 0.7987\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8306 - val_loss: 0.4259 - val_accuracy: 0.7987\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3627 - accuracy: 0.8388 - val_loss: 0.4258 - val_accuracy: 0.7987\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3612 - accuracy: 0.8355 - val_loss: 0.4257 - val_accuracy: 0.7987\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8339 - val_loss: 0.4277 - val_accuracy: 0.7987\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8322 - val_loss: 0.4254 - val_accuracy: 0.7987\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3617 - accuracy: 0.8388 - val_loss: 0.4277 - val_accuracy: 0.7987\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3607 - accuracy: 0.8355 - val_loss: 0.4282 - val_accuracy: 0.7987\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8453 - val_loss: 0.4271 - val_accuracy: 0.7987\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3579 - accuracy: 0.8404 - val_loss: 0.4260 - val_accuracy: 0.7987\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3590 - accuracy: 0.8388 - val_loss: 0.4300 - val_accuracy: 0.7922\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8388 - val_loss: 0.4289 - val_accuracy: 0.7987\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3585 - accuracy: 0.8404 - val_loss: 0.4296 - val_accuracy: 0.7987\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8404 - val_loss: 0.4308 - val_accuracy: 0.7987\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8371 - val_loss: 0.4317 - val_accuracy: 0.7922\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8371 - val_loss: 0.4311 - val_accuracy: 0.7987\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8420 - val_loss: 0.4304 - val_accuracy: 0.7987\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.8469 - val_loss: 0.4303 - val_accuracy: 0.7987\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8453 - val_loss: 0.4323 - val_accuracy: 0.7987\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8436 - val_loss: 0.4300 - val_accuracy: 0.7922\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8453 - val_loss: 0.4300 - val_accuracy: 0.7987\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.8502 - val_loss: 0.4339 - val_accuracy: 0.7987\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8518 - val_loss: 0.4318 - val_accuracy: 0.7922\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8550 - val_loss: 0.4320 - val_accuracy: 0.7922\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.8534 - val_loss: 0.4295 - val_accuracy: 0.7987\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.8534 - val_loss: 0.4300 - val_accuracy: 0.7987\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8567 - val_loss: 0.4325 - val_accuracy: 0.7987\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.8567 - val_loss: 0.4308 - val_accuracy: 0.7987\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8534 - val_loss: 0.4307 - val_accuracy: 0.7922\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8518 - val_loss: 0.4334 - val_accuracy: 0.7922\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8453 - val_loss: 0.4352 - val_accuracy: 0.7922\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.8518 - val_loss: 0.4328 - val_accuracy: 0.7922\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3456 - accuracy: 0.8518 - val_loss: 0.4315 - val_accuracy: 0.7987\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8518 - val_loss: 0.4314 - val_accuracy: 0.7987\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8583 - val_loss: 0.4341 - val_accuracy: 0.7922\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8518 - val_loss: 0.4373 - val_accuracy: 0.7987\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8502 - val_loss: 0.4352 - val_accuracy: 0.7922\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8567 - val_loss: 0.4356 - val_accuracy: 0.7922\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8616 - val_loss: 0.4322 - val_accuracy: 0.7922\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8599 - val_loss: 0.4335 - val_accuracy: 0.7987\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8518 - val_loss: 0.4391 - val_accuracy: 0.7922\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8583 - val_loss: 0.4387 - val_accuracy: 0.7922\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8664 - val_loss: 0.4376 - val_accuracy: 0.7922\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8616 - val_loss: 0.4385 - val_accuracy: 0.7857\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8616 - val_loss: 0.4372 - val_accuracy: 0.7922\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8616 - val_loss: 0.4366 - val_accuracy: 0.7922\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8534 - val_loss: 0.4359 - val_accuracy: 0.7987\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8550 - val_loss: 0.4376 - val_accuracy: 0.7922\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8534 - val_loss: 0.4392 - val_accuracy: 0.7922\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.8550 - val_loss: 0.4379 - val_accuracy: 0.7922\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8583 - val_loss: 0.4413 - val_accuracy: 0.7857\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8583 - val_loss: 0.4403 - val_accuracy: 0.7922\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.8648 - val_loss: 0.4422 - val_accuracy: 0.7857\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8681 - val_loss: 0.4412 - val_accuracy: 0.7857\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8648 - val_loss: 0.4416 - val_accuracy: 0.7922\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8599 - val_loss: 0.4398 - val_accuracy: 0.7857\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8599 - val_loss: 0.4420 - val_accuracy: 0.7857\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8550 - val_loss: 0.4375 - val_accuracy: 0.7922\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8550 - val_loss: 0.4368 - val_accuracy: 0.7922\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3323 - accuracy: 0.8567 - val_loss: 0.4380 - val_accuracy: 0.7922\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8616 - val_loss: 0.4392 - val_accuracy: 0.7922\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.8599 - val_loss: 0.4399 - val_accuracy: 0.7922\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8648 - val_loss: 0.4405 - val_accuracy: 0.7922\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3310 - accuracy: 0.8664 - val_loss: 0.4417 - val_accuracy: 0.7857\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8616 - val_loss: 0.4406 - val_accuracy: 0.7857\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8648 - val_loss: 0.4395 - val_accuracy: 0.7922\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3286 - accuracy: 0.8762 - val_loss: 0.4423 - val_accuracy: 0.7987\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8713 - val_loss: 0.4425 - val_accuracy: 0.7857\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.8681 - val_loss: 0.4431 - val_accuracy: 0.7922\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.8713 - val_loss: 0.4458 - val_accuracy: 0.7857\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3269 - accuracy: 0.8730 - val_loss: 0.4434 - val_accuracy: 0.7922\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8648 - val_loss: 0.4452 - val_accuracy: 0.7922\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3263 - accuracy: 0.8648 - val_loss: 0.4423 - val_accuracy: 0.7922\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3257 - accuracy: 0.8616 - val_loss: 0.4415 - val_accuracy: 0.7922\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.8664 - val_loss: 0.4413 - val_accuracy: 0.7922\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3241 - accuracy: 0.8632 - val_loss: 0.4449 - val_accuracy: 0.7857\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3242 - accuracy: 0.8697 - val_loss: 0.4457 - val_accuracy: 0.7922\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3238 - accuracy: 0.8632 - val_loss: 0.4433 - val_accuracy: 0.7922\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3228 - accuracy: 0.8697 - val_loss: 0.4437 - val_accuracy: 0.7922\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3236 - accuracy: 0.8697 - val_loss: 0.4427 - val_accuracy: 0.7922\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3212 - accuracy: 0.8697 - val_loss: 0.4493 - val_accuracy: 0.7857\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3231 - accuracy: 0.8697 - val_loss: 0.4456 - val_accuracy: 0.7857\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8713 - val_loss: 0.4464 - val_accuracy: 0.7922\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3220 - accuracy: 0.8681 - val_loss: 0.4548 - val_accuracy: 0.8052\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3214 - accuracy: 0.8648 - val_loss: 0.4453 - val_accuracy: 0.7922\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ac92a118910>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Val Accuracy = 79.22%"
      ],
      "metadata": {
        "id": "R5_kh072m912"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. No. of Layer Hyerper Tunning\n",
        "\n",
        "## Step 1 : Building the Function\n",
        "## In case of layer we need to work on look and we ue hp2.Int(<name>, start, stop, step) for selecting the layer\n",
        "\n",
        "def build_model2(hp2):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  count = 0 # To use the as counter\n",
        "\n",
        "  for i in range(hp2.Int('Layer', 1,10)):\n",
        "    if count==0:\n",
        "      model.add(Dense(128, activation= 'relu', input_dim=8)) # To define the inputs if counter is 0\n",
        "    else:\n",
        "      model.add(Dense(128, activation = 'relu'))\n",
        "    count+=1\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "VM7HZovQKubt"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2 : Creating the Tunner Object\n",
        "\n",
        "\n",
        "tuner2 = kt.RandomSearch( build_model2,\n",
        "                         objective = 'val_accuracy',\n",
        "                          max_trials=5,\n",
        "                          directory = 'mydir',\n",
        "                          project_name = 'Layers_Tunning')\n"
      ],
      "metadata": {
        "id": "Gd-nHELxMuGI"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3: Passing Data to the tunner\n",
        "\n",
        "tuner2.search(x_train, y_train , epochs=5 , validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf5wluvTNBFh",
        "outputId": "8accc4aa-47dc-48c2-9a21-94f2283043cc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 04s]\n",
            "val_accuracy: 0.8051947951316833\n",
            "\n",
            "Best val_accuracy So Far: 0.8181818127632141\n",
            "Total elapsed time: 00h 00m 21s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking Best_parameters\n",
        "\n",
        "tuner2.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAWuFOqlNTdH",
        "outputId": "5978b814-2823-4844-a9bd-cc1f54ea987e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Layer': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating Model with Tunner Results and Fitting the Model\n",
        "\n",
        "model2 = tuner2.get_best_models(num_models=1)[0]\n",
        "model2.fit(x_train, y_train, epochs=200 , initial_epoch=5, validation_data = (x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9lxWGMDNrCq",
        "outputId": "17c8889b-427e-4402-900c-cfd869df0792"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/200\n",
            "20/20 [==============================] - 2s 18ms/step - loss: 0.4249 - accuracy: 0.7948 - val_loss: 0.4369 - val_accuracy: 0.8052\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8094 - val_loss: 0.4182 - val_accuracy: 0.7922\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8241 - val_loss: 0.4237 - val_accuracy: 0.7727\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8127 - val_loss: 0.4278 - val_accuracy: 0.7792\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8322 - val_loss: 0.4292 - val_accuracy: 0.7922\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3519 - accuracy: 0.8339 - val_loss: 0.4387 - val_accuracy: 0.8117\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8241 - val_loss: 0.4701 - val_accuracy: 0.8052\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3608 - accuracy: 0.8502 - val_loss: 0.4755 - val_accuracy: 0.7597\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3304 - accuracy: 0.8420 - val_loss: 0.4668 - val_accuracy: 0.7987\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2994 - accuracy: 0.8632 - val_loss: 0.6086 - val_accuracy: 0.7922\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2784 - accuracy: 0.8779 - val_loss: 0.5590 - val_accuracy: 0.7208\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2819 - accuracy: 0.8844 - val_loss: 0.5578 - val_accuracy: 0.7468\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3399 - accuracy: 0.8518 - val_loss: 0.4789 - val_accuracy: 0.7403\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2884 - accuracy: 0.8762 - val_loss: 0.6500 - val_accuracy: 0.7857\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2677 - accuracy: 0.8941 - val_loss: 0.5827 - val_accuracy: 0.7208\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2253 - accuracy: 0.8958 - val_loss: 0.7381 - val_accuracy: 0.7532\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2443 - accuracy: 0.9039 - val_loss: 0.8006 - val_accuracy: 0.7273\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2593 - accuracy: 0.8844 - val_loss: 0.6516 - val_accuracy: 0.7857\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2046 - accuracy: 0.9072 - val_loss: 0.7842 - val_accuracy: 0.7597\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.1600 - accuracy: 0.9349 - val_loss: 0.8900 - val_accuracy: 0.7338\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.1556 - accuracy: 0.9365 - val_loss: 0.9524 - val_accuracy: 0.7403\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1602 - accuracy: 0.9365 - val_loss: 1.0083 - val_accuracy: 0.7597\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2747 - accuracy: 0.8827 - val_loss: 0.5921 - val_accuracy: 0.7792\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.1952 - accuracy: 0.9202 - val_loss: 0.7441 - val_accuracy: 0.7403\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1340 - accuracy: 0.9511 - val_loss: 1.0966 - val_accuracy: 0.7273\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9772 - val_loss: 1.5341 - val_accuracy: 0.6883\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1291 - accuracy: 0.9560 - val_loss: 1.2484 - val_accuracy: 0.7013\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9316 - val_loss: 1.1454 - val_accuracy: 0.7143\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1354 - accuracy: 0.9446 - val_loss: 1.2735 - val_accuracy: 0.7338\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1446 - accuracy: 0.9544 - val_loss: 1.1399 - val_accuracy: 0.6948\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1355 - accuracy: 0.9495 - val_loss: 1.0229 - val_accuracy: 0.7013\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1200 - accuracy: 0.9511 - val_loss: 1.0203 - val_accuracy: 0.7597\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0807 - accuracy: 0.9658 - val_loss: 1.2985 - val_accuracy: 0.7208\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0917 - accuracy: 0.9707 - val_loss: 1.1704 - val_accuracy: 0.7273\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0598 - accuracy: 0.9788 - val_loss: 1.4662 - val_accuracy: 0.7468\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0283 - accuracy: 0.9919 - val_loss: 1.8037 - val_accuracy: 0.7273\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0436 - accuracy: 0.9853 - val_loss: 1.3783 - val_accuracy: 0.6948\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0423 - accuracy: 0.9788 - val_loss: 1.7012 - val_accuracy: 0.7532\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0629 - accuracy: 0.9853 - val_loss: 1.5140 - val_accuracy: 0.7468\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1806 - accuracy: 0.9267 - val_loss: 0.8534 - val_accuracy: 0.7662\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1559 - accuracy: 0.9446 - val_loss: 1.0453 - val_accuracy: 0.7403\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0798 - accuracy: 0.9707 - val_loss: 1.2685 - val_accuracy: 0.7208\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0460 - accuracy: 0.9870 - val_loss: 1.5952 - val_accuracy: 0.7338\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0378 - accuracy: 0.9870 - val_loss: 1.9127 - val_accuracy: 0.7273\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1331 - accuracy: 0.9674 - val_loss: 1.0313 - val_accuracy: 0.7078\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0898 - accuracy: 0.9723 - val_loss: 1.1834 - val_accuracy: 0.7532\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1018 - accuracy: 0.9642 - val_loss: 1.2473 - val_accuracy: 0.7857\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1013 - accuracy: 0.9658 - val_loss: 0.9396 - val_accuracy: 0.7143\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0548 - accuracy: 0.9805 - val_loss: 1.3424 - val_accuracy: 0.7208\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 0.9935 - val_loss: 1.6949 - val_accuracy: 0.7403\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 1.9779 - val_accuracy: 0.7273\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9886 - val_loss: 1.7362 - val_accuracy: 0.7468\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 1.6147 - val_accuracy: 0.7468\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9870 - val_loss: 1.4713 - val_accuracy: 0.7597\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0167 - accuracy: 0.9967 - val_loss: 1.6488 - val_accuracy: 0.7532\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0144 - accuracy: 0.9919 - val_loss: 1.8532 - val_accuracy: 0.7532\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 2.0047 - val_accuracy: 0.7597\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 2.2334 - val_accuracy: 0.7532\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 2.4443 - val_accuracy: 0.7403\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 0.9984 - val_loss: 2.4690 - val_accuracy: 0.7403\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 6.1548e-04 - accuracy: 1.0000 - val_loss: 2.6197 - val_accuracy: 0.7403\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 3.4452e-04 - accuracy: 1.0000 - val_loss: 2.7835 - val_accuracy: 0.7403\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 2.1619e-04 - accuracy: 1.0000 - val_loss: 2.9239 - val_accuracy: 0.7403\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.4213e-04 - accuracy: 1.0000 - val_loss: 3.0260 - val_accuracy: 0.7468\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.0453e-04 - accuracy: 1.0000 - val_loss: 3.1218 - val_accuracy: 0.7468\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 7.8723e-05 - accuracy: 1.0000 - val_loss: 3.2123 - val_accuracy: 0.7468\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 6.2382e-05 - accuracy: 1.0000 - val_loss: 3.3373 - val_accuracy: 0.7468\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 4.4866e-05 - accuracy: 1.0000 - val_loss: 3.4255 - val_accuracy: 0.7403\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 3.7044e-05 - accuracy: 1.0000 - val_loss: 3.5141 - val_accuracy: 0.7403\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 3.0184e-05 - accuracy: 1.0000 - val_loss: 3.5866 - val_accuracy: 0.7403\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 2.4907e-05 - accuracy: 1.0000 - val_loss: 3.6606 - val_accuracy: 0.7403\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 2.1292e-05 - accuracy: 1.0000 - val_loss: 3.7231 - val_accuracy: 0.7403\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.8214e-05 - accuracy: 1.0000 - val_loss: 3.8158 - val_accuracy: 0.7403\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.4493e-05 - accuracy: 1.0000 - val_loss: 3.8890 - val_accuracy: 0.7403\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.1846e-05 - accuracy: 1.0000 - val_loss: 3.9760 - val_accuracy: 0.7403\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 9.4111e-06 - accuracy: 1.0000 - val_loss: 4.0552 - val_accuracy: 0.7403\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 7.5806e-06 - accuracy: 1.0000 - val_loss: 4.1551 - val_accuracy: 0.7403\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 6.2724e-06 - accuracy: 1.0000 - val_loss: 4.2521 - val_accuracy: 0.7403\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 4.9748e-06 - accuracy: 1.0000 - val_loss: 4.3342 - val_accuracy: 0.7468\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 4.1041e-06 - accuracy: 1.0000 - val_loss: 4.4021 - val_accuracy: 0.7403\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 3.5039e-06 - accuracy: 1.0000 - val_loss: 4.4704 - val_accuracy: 0.7468\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 2.9834e-06 - accuracy: 1.0000 - val_loss: 4.5331 - val_accuracy: 0.7468\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 2.6138e-06 - accuracy: 1.0000 - val_loss: 4.6003 - val_accuracy: 0.7532\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 2.2625e-06 - accuracy: 1.0000 - val_loss: 4.6513 - val_accuracy: 0.7532\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 2.0201e-06 - accuracy: 1.0000 - val_loss: 4.7001 - val_accuracy: 0.7532\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.8564e-06 - accuracy: 1.0000 - val_loss: 4.7457 - val_accuracy: 0.7532\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.6144e-06 - accuracy: 1.0000 - val_loss: 4.8035 - val_accuracy: 0.7532\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.4718e-06 - accuracy: 1.0000 - val_loss: 4.8501 - val_accuracy: 0.7532\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.3499e-06 - accuracy: 1.0000 - val_loss: 4.8870 - val_accuracy: 0.7532\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.2390e-06 - accuracy: 1.0000 - val_loss: 4.9387 - val_accuracy: 0.7468\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.1311e-06 - accuracy: 1.0000 - val_loss: 4.9716 - val_accuracy: 0.7532\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.0492e-06 - accuracy: 1.0000 - val_loss: 5.0074 - val_accuracy: 0.7532\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 9.6512e-07 - accuracy: 1.0000 - val_loss: 5.0375 - val_accuracy: 0.7532\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 9.0801e-07 - accuracy: 1.0000 - val_loss: 5.0680 - val_accuracy: 0.7532\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 8.5301e-07 - accuracy: 1.0000 - val_loss: 5.1009 - val_accuracy: 0.7468\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 7.9377e-07 - accuracy: 1.0000 - val_loss: 5.1295 - val_accuracy: 0.7532\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 7.5068e-07 - accuracy: 1.0000 - val_loss: 5.1558 - val_accuracy: 0.7532\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 7.0705e-07 - accuracy: 1.0000 - val_loss: 5.1806 - val_accuracy: 0.7532\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 6.7102e-07 - accuracy: 1.0000 - val_loss: 5.2069 - val_accuracy: 0.7468\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 6.3513e-07 - accuracy: 1.0000 - val_loss: 5.2321 - val_accuracy: 0.7468\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5.9579e-07 - accuracy: 1.0000 - val_loss: 5.2574 - val_accuracy: 0.7532\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5.6495e-07 - accuracy: 1.0000 - val_loss: 5.2818 - val_accuracy: 0.7532\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5.3848e-07 - accuracy: 1.0000 - val_loss: 5.3058 - val_accuracy: 0.7532\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5.1296e-07 - accuracy: 1.0000 - val_loss: 5.3256 - val_accuracy: 0.7532\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 4.8948e-07 - accuracy: 1.0000 - val_loss: 5.3481 - val_accuracy: 0.7532\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 4.6903e-07 - accuracy: 1.0000 - val_loss: 5.3728 - val_accuracy: 0.7532\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 4.4474e-07 - accuracy: 1.0000 - val_loss: 5.3908 - val_accuracy: 0.7532\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 4.2868e-07 - accuracy: 1.0000 - val_loss: 5.4134 - val_accuracy: 0.7532\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 4.0607e-07 - accuracy: 1.0000 - val_loss: 5.4350 - val_accuracy: 0.7532\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 3.9001e-07 - accuracy: 1.0000 - val_loss: 5.4549 - val_accuracy: 0.7532\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 3.7399e-07 - accuracy: 1.0000 - val_loss: 5.4735 - val_accuracy: 0.7532\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 3.5812e-07 - accuracy: 1.0000 - val_loss: 5.4898 - val_accuracy: 0.7532\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 3.4848e-07 - accuracy: 1.0000 - val_loss: 5.5101 - val_accuracy: 0.7532\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 3.3262e-07 - accuracy: 1.0000 - val_loss: 5.5404 - val_accuracy: 0.7468\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 3.1872e-07 - accuracy: 1.0000 - val_loss: 5.5571 - val_accuracy: 0.7468\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 3.0801e-07 - accuracy: 1.0000 - val_loss: 5.5726 - val_accuracy: 0.7468\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 2.9663e-07 - accuracy: 1.0000 - val_loss: 5.5874 - val_accuracy: 0.7468\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 2.8757e-07 - accuracy: 1.0000 - val_loss: 5.6009 - val_accuracy: 0.7468\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 2.7847e-07 - accuracy: 1.0000 - val_loss: 5.6166 - val_accuracy: 0.7468\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 2.7106e-07 - accuracy: 1.0000 - val_loss: 5.6323 - val_accuracy: 0.7468\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 2.6082e-07 - accuracy: 1.0000 - val_loss: 5.6463 - val_accuracy: 0.7468\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 2.5314e-07 - accuracy: 1.0000 - val_loss: 5.6602 - val_accuracy: 0.7468\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 2.4523e-07 - accuracy: 1.0000 - val_loss: 5.6776 - val_accuracy: 0.7468\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 2.3749e-07 - accuracy: 1.0000 - val_loss: 5.6907 - val_accuracy: 0.7468\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 2.3075e-07 - accuracy: 1.0000 - val_loss: 5.7041 - val_accuracy: 0.7468\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 2.2403e-07 - accuracy: 1.0000 - val_loss: 5.7180 - val_accuracy: 0.7468\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 2.1771e-07 - accuracy: 1.0000 - val_loss: 5.7311 - val_accuracy: 0.7468\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 2.1174e-07 - accuracy: 1.0000 - val_loss: 5.7427 - val_accuracy: 0.7468\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 2.0551e-07 - accuracy: 1.0000 - val_loss: 5.7561 - val_accuracy: 0.7468\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 2.0131e-07 - accuracy: 1.0000 - val_loss: 5.7689 - val_accuracy: 0.7468\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.9511e-07 - accuracy: 1.0000 - val_loss: 5.7794 - val_accuracy: 0.7532\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.8911e-07 - accuracy: 1.0000 - val_loss: 5.7924 - val_accuracy: 0.7468\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.8538e-07 - accuracy: 1.0000 - val_loss: 5.8057 - val_accuracy: 0.7468\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.7976e-07 - accuracy: 1.0000 - val_loss: 5.8172 - val_accuracy: 0.7468\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.7524e-07 - accuracy: 1.0000 - val_loss: 5.8290 - val_accuracy: 0.7468\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.7040e-07 - accuracy: 1.0000 - val_loss: 5.8407 - val_accuracy: 0.7468\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.6577e-07 - accuracy: 1.0000 - val_loss: 5.8565 - val_accuracy: 0.7532\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.6096e-07 - accuracy: 1.0000 - val_loss: 5.8681 - val_accuracy: 0.7532\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.5669e-07 - accuracy: 1.0000 - val_loss: 5.8791 - val_accuracy: 0.7468\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.5312e-07 - accuracy: 1.0000 - val_loss: 5.8894 - val_accuracy: 0.7468\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.4974e-07 - accuracy: 1.0000 - val_loss: 5.9000 - val_accuracy: 0.7532\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.4604e-07 - accuracy: 1.0000 - val_loss: 5.9128 - val_accuracy: 0.7532\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.4156e-07 - accuracy: 1.0000 - val_loss: 5.9306 - val_accuracy: 0.7468\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.3823e-07 - accuracy: 1.0000 - val_loss: 5.9421 - val_accuracy: 0.7468\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.3533e-07 - accuracy: 1.0000 - val_loss: 5.9527 - val_accuracy: 0.7468\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.3234e-07 - accuracy: 1.0000 - val_loss: 5.9630 - val_accuracy: 0.7468\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.2942e-07 - accuracy: 1.0000 - val_loss: 5.9709 - val_accuracy: 0.7468\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.2676e-07 - accuracy: 1.0000 - val_loss: 5.9826 - val_accuracy: 0.7468\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.2370e-07 - accuracy: 1.0000 - val_loss: 5.9924 - val_accuracy: 0.7468\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.2128e-07 - accuracy: 1.0000 - val_loss: 6.0029 - val_accuracy: 0.7468\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.1843e-07 - accuracy: 1.0000 - val_loss: 6.0118 - val_accuracy: 0.7468\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.1615e-07 - accuracy: 1.0000 - val_loss: 6.0217 - val_accuracy: 0.7468\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.1362e-07 - accuracy: 1.0000 - val_loss: 6.0312 - val_accuracy: 0.7468\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.1060e-07 - accuracy: 1.0000 - val_loss: 6.0431 - val_accuracy: 0.7468\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.0836e-07 - accuracy: 1.0000 - val_loss: 6.0557 - val_accuracy: 0.7468\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.0557e-07 - accuracy: 1.0000 - val_loss: 6.0641 - val_accuracy: 0.7468\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.0366e-07 - accuracy: 1.0000 - val_loss: 6.0739 - val_accuracy: 0.7468\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.0150e-07 - accuracy: 1.0000 - val_loss: 6.0826 - val_accuracy: 0.7468\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 9.9668e-08 - accuracy: 1.0000 - val_loss: 6.0921 - val_accuracy: 0.7468\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 9.7503e-08 - accuracy: 1.0000 - val_loss: 6.1014 - val_accuracy: 0.7468\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 9.5664e-08 - accuracy: 1.0000 - val_loss: 6.1106 - val_accuracy: 0.7468\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 9.3973e-08 - accuracy: 1.0000 - val_loss: 6.1206 - val_accuracy: 0.7468\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 9.2060e-08 - accuracy: 1.0000 - val_loss: 6.1287 - val_accuracy: 0.7468\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 9.0274e-08 - accuracy: 1.0000 - val_loss: 6.1382 - val_accuracy: 0.7468\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 8.8585e-08 - accuracy: 1.0000 - val_loss: 6.1459 - val_accuracy: 0.7468\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 8.6981e-08 - accuracy: 1.0000 - val_loss: 6.1542 - val_accuracy: 0.7468\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 8.5498e-08 - accuracy: 1.0000 - val_loss: 6.1639 - val_accuracy: 0.7468\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 8.4000e-08 - accuracy: 1.0000 - val_loss: 6.1712 - val_accuracy: 0.7468\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 8.2391e-08 - accuracy: 1.0000 - val_loss: 6.1809 - val_accuracy: 0.7468\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 8.0983e-08 - accuracy: 1.0000 - val_loss: 6.1879 - val_accuracy: 0.7468\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 7.9370e-08 - accuracy: 1.0000 - val_loss: 6.1963 - val_accuracy: 0.7468\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 7.7995e-08 - accuracy: 1.0000 - val_loss: 6.2054 - val_accuracy: 0.7468\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 7.6766e-08 - accuracy: 1.0000 - val_loss: 6.2148 - val_accuracy: 0.7468\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 7.5226e-08 - accuracy: 1.0000 - val_loss: 6.2218 - val_accuracy: 0.7468\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 7.4111e-08 - accuracy: 1.0000 - val_loss: 6.2292 - val_accuracy: 0.7468\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 7.2648e-08 - accuracy: 1.0000 - val_loss: 6.2379 - val_accuracy: 0.7468\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 7.1143e-08 - accuracy: 1.0000 - val_loss: 6.2485 - val_accuracy: 0.7532\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 6.9548e-08 - accuracy: 1.0000 - val_loss: 6.2576 - val_accuracy: 0.7468\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 6.8494e-08 - accuracy: 1.0000 - val_loss: 6.2675 - val_accuracy: 0.7468\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 6.7129e-08 - accuracy: 1.0000 - val_loss: 6.2757 - val_accuracy: 0.7468\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 6.5929e-08 - accuracy: 1.0000 - val_loss: 6.2816 - val_accuracy: 0.7468\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 6.4959e-08 - accuracy: 1.0000 - val_loss: 6.2908 - val_accuracy: 0.7468\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 6.3921e-08 - accuracy: 1.0000 - val_loss: 6.2967 - val_accuracy: 0.7532\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 6.2749e-08 - accuracy: 1.0000 - val_loss: 6.3059 - val_accuracy: 0.7468\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 6.1771e-08 - accuracy: 1.0000 - val_loss: 6.3137 - val_accuracy: 0.7468\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 6.0656e-08 - accuracy: 1.0000 - val_loss: 6.3207 - val_accuracy: 0.7468\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5.9705e-08 - accuracy: 1.0000 - val_loss: 6.3296 - val_accuracy: 0.7532\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5.8379e-08 - accuracy: 1.0000 - val_loss: 6.3372 - val_accuracy: 0.7532\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5.7403e-08 - accuracy: 1.0000 - val_loss: 6.3451 - val_accuracy: 0.7532\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 5.6467e-08 - accuracy: 1.0000 - val_loss: 6.3523 - val_accuracy: 0.7532\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 5.5571e-08 - accuracy: 1.0000 - val_loss: 6.3588 - val_accuracy: 0.7532\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5.4722e-08 - accuracy: 1.0000 - val_loss: 6.3665 - val_accuracy: 0.7532\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 5.3889e-08 - accuracy: 1.0000 - val_loss: 6.3735 - val_accuracy: 0.7532\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 5.3089e-08 - accuracy: 1.0000 - val_loss: 6.3812 - val_accuracy: 0.7532\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5.2236e-08 - accuracy: 1.0000 - val_loss: 6.3883 - val_accuracy: 0.7532\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ac91a253df0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Val_Accuracy = 75.32"
      ],
      "metadata": {
        "id": "fAKUu1yMqrvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Hyper Tunning Optimizer, Neurons, Layers, Activation Function in on Funcuton\n",
        "\n",
        "## Step1 : Creating a function\n",
        "\n",
        "def build_model_all(hp_all):\n",
        "\n",
        "  model = Sequential()\n",
        "  counter  = 0\n",
        "\n",
        "  for i in range(hp_all.Int('Layers', 1,10)):\n",
        "\n",
        "    if counter == 0:\n",
        "\n",
        "      model.add(Dense(hp_all.Int('Neurons'+ str(i),min_value = 1,max_value = 128,step = 8),\n",
        "                      activation = hp_all.Choice('Activation'+ str(i), values= ['sigmoid', 'tanh', 'relu']),\n",
        "                      input_dim=8))\n",
        "    else :\n",
        "\n",
        "      model.add(Dense(hp_all.Int('Neurons'+str(i), min_value = 1,max_value = 128,step = 8),\n",
        "                      activation = hp_all.Choice('Activation'+str(i), values = ['sigmoid', 'tanh', 'relu'])))\n",
        "    counter +=1\n",
        "\n",
        "  model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "  model.compile(optimizer = hp_all.Choice('Optimizer', values = ['adam', 'rmsprop', 'SGD', 'adadelta']),\n",
        "                 loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "asbzkgDRN62Z"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2 : Creating A Tuner Object\n",
        "\n",
        "tuner3 = kt.RandomSearch(build_model_all,\n",
        "                         objective = 'val_accuracy',\n",
        "                         max_trials = 5,\n",
        "                         directory = 'mydir',\n",
        "                         project_name = 'Tune_All')"
      ],
      "metadata": {
        "id": "Eo4QVsPBREoB"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Passing Data to the Tunner\n",
        "\n",
        "tuner3.search(x_train,y_train, epochs=5, validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gMTcdWOTKtU",
        "outputId": "5ca04bae-6298-431c-e778-a322d5fee216"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 02s]\n",
            "val_accuracy: 0.6428571343421936\n",
            "\n",
            "Best val_accuracy So Far: 0.8051947951316833\n",
            "Total elapsed time: 00h 00m 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking the best parameters\n",
        "\n",
        "tuner3.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtC329STUV8w",
        "outputId": "b5f83b18-0b2e-4ea2-e3ab-903b9a345ab2"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Layers': 6,\n",
              " 'Neurons0': 25,\n",
              " 'Activation0': 'relu',\n",
              " 'Optimizer': 'rmsprop',\n",
              " 'Neurons1': 49,\n",
              " 'Activation1': 'tanh',\n",
              " 'Neurons2': 9,\n",
              " 'Activation2': 'relu',\n",
              " 'Neurons3': 57,\n",
              " 'Activation3': 'relu',\n",
              " 'Neurons4': 1,\n",
              " 'Activation4': 'relu',\n",
              " 'Neurons5': 65,\n",
              " 'Activation5': 'tanh',\n",
              " 'Neurons6': 41,\n",
              " 'Activation6': 'tanh'}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Building Model with Tunner Input\n",
        "\n",
        "model = tuner3.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "6oOjXs4XUkNb"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Fitting the Model\n",
        "\n",
        "model.fit(x_train, y_train ,epochs = 200 , initial_epoch =5, validation_data= (x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7JWgPSRU-AY",
        "outputId": "9674af9a-3717-4dbf-82d7-b9975d8e6cad"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/200\n",
            "20/20 [==============================] - 2s 16ms/step - loss: 0.4917 - accuracy: 0.7655 - val_loss: 0.4737 - val_accuracy: 0.8117\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.7704 - val_loss: 0.4627 - val_accuracy: 0.8182\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7687 - val_loss: 0.4515 - val_accuracy: 0.7987\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7671 - val_loss: 0.4441 - val_accuracy: 0.7922\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7606 - val_loss: 0.4393 - val_accuracy: 0.7922\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7752 - val_loss: 0.4387 - val_accuracy: 0.8052\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7671 - val_loss: 0.4312 - val_accuracy: 0.8052\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7850 - val_loss: 0.4428 - val_accuracy: 0.7857\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.7834 - val_loss: 0.4253 - val_accuracy: 0.8052\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7866 - val_loss: 0.4389 - val_accuracy: 0.7987\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7720 - val_loss: 0.4200 - val_accuracy: 0.7857\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7915 - val_loss: 0.4205 - val_accuracy: 0.8052\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7834 - val_loss: 0.4235 - val_accuracy: 0.8052\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7932 - val_loss: 0.4287 - val_accuracy: 0.7922\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7948 - val_loss: 0.4269 - val_accuracy: 0.7922\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7932 - val_loss: 0.4209 - val_accuracy: 0.7857\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7883 - val_loss: 0.4239 - val_accuracy: 0.7792\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.7997 - val_loss: 0.4196 - val_accuracy: 0.7857\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7915 - val_loss: 0.4199 - val_accuracy: 0.7857\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.7997 - val_loss: 0.4292 - val_accuracy: 0.7987\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.7964 - val_loss: 0.4275 - val_accuracy: 0.7857\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8078 - val_loss: 0.4451 - val_accuracy: 0.7727\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8127 - val_loss: 0.4175 - val_accuracy: 0.7857\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.7932 - val_loss: 0.4235 - val_accuracy: 0.7857\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8094 - val_loss: 0.4494 - val_accuracy: 0.7922\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8078 - val_loss: 0.4201 - val_accuracy: 0.7922\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3884 - accuracy: 0.8111 - val_loss: 0.4243 - val_accuracy: 0.7792\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8176 - val_loss: 0.4454 - val_accuracy: 0.7792\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8062 - val_loss: 0.4473 - val_accuracy: 0.7857\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8176 - val_loss: 0.4431 - val_accuracy: 0.7857\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8192 - val_loss: 0.4498 - val_accuracy: 0.7727\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8257 - val_loss: 0.4309 - val_accuracy: 0.7727\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3665 - accuracy: 0.8290 - val_loss: 0.4354 - val_accuracy: 0.7857\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3647 - accuracy: 0.8257 - val_loss: 0.4377 - val_accuracy: 0.7792\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3645 - accuracy: 0.8225 - val_loss: 0.4365 - val_accuracy: 0.7792\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3612 - accuracy: 0.8306 - val_loss: 0.4455 - val_accuracy: 0.7727\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3551 - accuracy: 0.8355 - val_loss: 0.4445 - val_accuracy: 0.7857\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3538 - accuracy: 0.8355 - val_loss: 0.4363 - val_accuracy: 0.7922\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3461 - accuracy: 0.8371 - val_loss: 0.4511 - val_accuracy: 0.7727\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3431 - accuracy: 0.8371 - val_loss: 0.4499 - val_accuracy: 0.7727\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3437 - accuracy: 0.8355 - val_loss: 0.4653 - val_accuracy: 0.7597\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3443 - accuracy: 0.8567 - val_loss: 0.4695 - val_accuracy: 0.7727\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3342 - accuracy: 0.8453 - val_loss: 0.4509 - val_accuracy: 0.7857\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8550 - val_loss: 0.4701 - val_accuracy: 0.7727\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3298 - accuracy: 0.8550 - val_loss: 0.4735 - val_accuracy: 0.7857\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3235 - accuracy: 0.8550 - val_loss: 0.4770 - val_accuracy: 0.7468\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3204 - accuracy: 0.8599 - val_loss: 0.4650 - val_accuracy: 0.7857\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3206 - accuracy: 0.8599 - val_loss: 0.4757 - val_accuracy: 0.7662\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3165 - accuracy: 0.8697 - val_loss: 0.4774 - val_accuracy: 0.7662\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3085 - accuracy: 0.8681 - val_loss: 0.4858 - val_accuracy: 0.7792\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3105 - accuracy: 0.8697 - val_loss: 0.5279 - val_accuracy: 0.7532\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3079 - accuracy: 0.8762 - val_loss: 0.5239 - val_accuracy: 0.7468\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3041 - accuracy: 0.8697 - val_loss: 0.4869 - val_accuracy: 0.7727\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2928 - accuracy: 0.8746 - val_loss: 0.4870 - val_accuracy: 0.7727\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2940 - accuracy: 0.8632 - val_loss: 0.4896 - val_accuracy: 0.7662\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2916 - accuracy: 0.8876 - val_loss: 0.4982 - val_accuracy: 0.7532\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2848 - accuracy: 0.8795 - val_loss: 0.5837 - val_accuracy: 0.7338\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2866 - accuracy: 0.8746 - val_loss: 0.5194 - val_accuracy: 0.7532\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2834 - accuracy: 0.8860 - val_loss: 0.5211 - val_accuracy: 0.7727\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2725 - accuracy: 0.8844 - val_loss: 0.5332 - val_accuracy: 0.7468\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2749 - accuracy: 0.8909 - val_loss: 0.5484 - val_accuracy: 0.7403\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2682 - accuracy: 0.8974 - val_loss: 0.5266 - val_accuracy: 0.7662\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2717 - accuracy: 0.8893 - val_loss: 0.5507 - val_accuracy: 0.7208\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2670 - accuracy: 0.8941 - val_loss: 0.5329 - val_accuracy: 0.7597\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.8909 - val_loss: 0.5422 - val_accuracy: 0.7468\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2558 - accuracy: 0.8974 - val_loss: 0.5149 - val_accuracy: 0.7792\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2544 - accuracy: 0.8941 - val_loss: 0.5384 - val_accuracy: 0.7532\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2570 - accuracy: 0.8941 - val_loss: 0.6419 - val_accuracy: 0.7143\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2576 - accuracy: 0.8893 - val_loss: 0.5772 - val_accuracy: 0.7273\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.9007 - val_loss: 0.5889 - val_accuracy: 0.7403\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2380 - accuracy: 0.8941 - val_loss: 0.6297 - val_accuracy: 0.7338\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2470 - accuracy: 0.9039 - val_loss: 0.6004 - val_accuracy: 0.7532\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2329 - accuracy: 0.9202 - val_loss: 0.6229 - val_accuracy: 0.7468\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2427 - accuracy: 0.9039 - val_loss: 0.5946 - val_accuracy: 0.7597\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.9023 - val_loss: 0.6101 - val_accuracy: 0.7597\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2362 - accuracy: 0.9072 - val_loss: 0.5743 - val_accuracy: 0.7597\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2261 - accuracy: 0.9104 - val_loss: 0.6913 - val_accuracy: 0.7078\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2242 - accuracy: 0.9104 - val_loss: 0.6543 - val_accuracy: 0.7338\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2213 - accuracy: 0.9251 - val_loss: 0.6604 - val_accuracy: 0.7662\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2247 - accuracy: 0.9104 - val_loss: 0.6258 - val_accuracy: 0.7662\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2139 - accuracy: 0.9202 - val_loss: 0.7552 - val_accuracy: 0.7597\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2240 - accuracy: 0.9202 - val_loss: 0.6678 - val_accuracy: 0.7403\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2130 - accuracy: 0.9104 - val_loss: 0.6620 - val_accuracy: 0.7597\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2032 - accuracy: 0.9218 - val_loss: 0.6983 - val_accuracy: 0.7273\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2086 - accuracy: 0.9153 - val_loss: 0.6646 - val_accuracy: 0.7338\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2034 - accuracy: 0.9267 - val_loss: 0.7191 - val_accuracy: 0.7208\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1997 - accuracy: 0.9300 - val_loss: 0.7046 - val_accuracy: 0.7338\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1921 - accuracy: 0.9267 - val_loss: 0.6909 - val_accuracy: 0.7338\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1993 - accuracy: 0.9218 - val_loss: 0.7224 - val_accuracy: 0.7403\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2021 - accuracy: 0.9202 - val_loss: 0.7536 - val_accuracy: 0.7403\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1872 - accuracy: 0.9365 - val_loss: 0.7316 - val_accuracy: 0.7468\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9137 - val_loss: 0.7468 - val_accuracy: 0.7468\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1871 - accuracy: 0.9316 - val_loss: 0.7189 - val_accuracy: 0.7208\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1854 - accuracy: 0.9235 - val_loss: 0.8040 - val_accuracy: 0.7403\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9267 - val_loss: 0.7635 - val_accuracy: 0.7532\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1718 - accuracy: 0.9316 - val_loss: 0.7565 - val_accuracy: 0.7078\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1878 - accuracy: 0.9300 - val_loss: 0.7600 - val_accuracy: 0.7468\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1698 - accuracy: 0.9267 - val_loss: 0.8369 - val_accuracy: 0.7273\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1665 - accuracy: 0.9332 - val_loss: 0.8707 - val_accuracy: 0.7662\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1658 - accuracy: 0.9365 - val_loss: 0.8579 - val_accuracy: 0.7338\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1720 - accuracy: 0.9479 - val_loss: 0.8344 - val_accuracy: 0.7468\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9365 - val_loss: 0.9573 - val_accuracy: 0.7403\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1591 - accuracy: 0.9463 - val_loss: 0.9066 - val_accuracy: 0.7273\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1554 - accuracy: 0.9446 - val_loss: 1.0115 - val_accuracy: 0.7468\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1645 - accuracy: 0.9300 - val_loss: 0.9319 - val_accuracy: 0.7208\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1709 - accuracy: 0.9316 - val_loss: 0.9161 - val_accuracy: 0.7532\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1531 - accuracy: 0.9365 - val_loss: 0.8761 - val_accuracy: 0.7078\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9381 - val_loss: 0.9819 - val_accuracy: 0.7338\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1514 - accuracy: 0.9381 - val_loss: 0.8864 - val_accuracy: 0.7338\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1420 - accuracy: 0.9528 - val_loss: 1.0635 - val_accuracy: 0.7273\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.9446 - val_loss: 0.9707 - val_accuracy: 0.7338\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1557 - accuracy: 0.9381 - val_loss: 0.9736 - val_accuracy: 0.7338\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1362 - accuracy: 0.9528 - val_loss: 1.1346 - val_accuracy: 0.7403\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1529 - accuracy: 0.9463 - val_loss: 0.9900 - val_accuracy: 0.7403\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1248 - accuracy: 0.9511 - val_loss: 0.9951 - val_accuracy: 0.7532\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1335 - accuracy: 0.9560 - val_loss: 1.0890 - val_accuracy: 0.7338\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1350 - accuracy: 0.9511 - val_loss: 1.0436 - val_accuracy: 0.7468\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9511 - val_loss: 1.0849 - val_accuracy: 0.7532\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1221 - accuracy: 0.9577 - val_loss: 1.1989 - val_accuracy: 0.7727\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1233 - accuracy: 0.9609 - val_loss: 1.0176 - val_accuracy: 0.7532\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1222 - accuracy: 0.9642 - val_loss: 1.1044 - val_accuracy: 0.7532\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.9593 - val_loss: 1.0596 - val_accuracy: 0.7338\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9691 - val_loss: 1.1029 - val_accuracy: 0.7597\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1234 - accuracy: 0.9577 - val_loss: 1.0482 - val_accuracy: 0.7532\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9577 - val_loss: 1.2135 - val_accuracy: 0.7597\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9625 - val_loss: 1.1963 - val_accuracy: 0.7727\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1142 - accuracy: 0.9609 - val_loss: 1.2396 - val_accuracy: 0.7597\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1050 - accuracy: 0.9642 - val_loss: 1.2734 - val_accuracy: 0.7468\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1158 - accuracy: 0.9577 - val_loss: 1.1898 - val_accuracy: 0.7338\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9691 - val_loss: 1.2963 - val_accuracy: 0.7468\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.9642 - val_loss: 1.2939 - val_accuracy: 0.7273\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.9658 - val_loss: 1.2168 - val_accuracy: 0.7662\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1031 - accuracy: 0.9658 - val_loss: 1.1952 - val_accuracy: 0.7338\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9658 - val_loss: 1.2164 - val_accuracy: 0.7403\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9691 - val_loss: 1.2154 - val_accuracy: 0.7532\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9707 - val_loss: 1.3665 - val_accuracy: 0.7403\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0919 - accuracy: 0.9739 - val_loss: 1.3767 - val_accuracy: 0.7403\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1046 - accuracy: 0.9642 - val_loss: 1.4690 - val_accuracy: 0.7403\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.9756 - val_loss: 1.4085 - val_accuracy: 0.7468\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0948 - accuracy: 0.9691 - val_loss: 1.3300 - val_accuracy: 0.7338\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9772 - val_loss: 1.3341 - val_accuracy: 0.7662\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0908 - accuracy: 0.9707 - val_loss: 1.4519 - val_accuracy: 0.7468\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9772 - val_loss: 1.4953 - val_accuracy: 0.7273\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9739 - val_loss: 1.2927 - val_accuracy: 0.7468\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0987 - accuracy: 0.9691 - val_loss: 1.5175 - val_accuracy: 0.7403\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9805 - val_loss: 1.4238 - val_accuracy: 0.7403\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9788 - val_loss: 1.5234 - val_accuracy: 0.7597\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9788 - val_loss: 1.5081 - val_accuracy: 0.7208\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9788 - val_loss: 1.5318 - val_accuracy: 0.7532\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9723 - val_loss: 1.3690 - val_accuracy: 0.7338\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.9853 - val_loss: 1.7625 - val_accuracy: 0.7597\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9756 - val_loss: 1.5517 - val_accuracy: 0.7338\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.9805 - val_loss: 1.6536 - val_accuracy: 0.7468\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9723 - val_loss: 1.5774 - val_accuracy: 0.7338\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9821 - val_loss: 1.6182 - val_accuracy: 0.7143\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9739 - val_loss: 1.7386 - val_accuracy: 0.7338\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0631 - accuracy: 0.9853 - val_loss: 1.6951 - val_accuracy: 0.7597\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0891 - accuracy: 0.9788 - val_loss: 1.7225 - val_accuracy: 0.7208\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0858 - accuracy: 0.9739 - val_loss: 1.6432 - val_accuracy: 0.7338\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9805 - val_loss: 1.6820 - val_accuracy: 0.7532\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0690 - accuracy: 0.9772 - val_loss: 1.7075 - val_accuracy: 0.7403\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0662 - accuracy: 0.9821 - val_loss: 1.6716 - val_accuracy: 0.7403\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0633 - accuracy: 0.9837 - val_loss: 1.6811 - val_accuracy: 0.7597\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.0728 - accuracy: 0.9821 - val_loss: 1.6373 - val_accuracy: 0.7338\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0790 - accuracy: 0.9772 - val_loss: 1.8356 - val_accuracy: 0.7208\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0629 - accuracy: 0.9837 - val_loss: 1.6838 - val_accuracy: 0.7338\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0629 - accuracy: 0.9837 - val_loss: 1.8380 - val_accuracy: 0.7338\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0689 - accuracy: 0.9805 - val_loss: 1.7612 - val_accuracy: 0.7532\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0633 - accuracy: 0.9821 - val_loss: 1.8113 - val_accuracy: 0.7468\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0990 - accuracy: 0.9723 - val_loss: 1.7869 - val_accuracy: 0.7532\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0549 - accuracy: 0.9886 - val_loss: 1.8745 - val_accuracy: 0.7468\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0568 - accuracy: 0.9853 - val_loss: 1.6690 - val_accuracy: 0.7662\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0961 - accuracy: 0.9707 - val_loss: 1.7443 - val_accuracy: 0.7468\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0660 - accuracy: 0.9772 - val_loss: 1.8230 - val_accuracy: 0.7273\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0564 - accuracy: 0.9837 - val_loss: 2.1001 - val_accuracy: 0.7338\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0656 - accuracy: 0.9788 - val_loss: 1.7872 - val_accuracy: 0.7013\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0758 - accuracy: 0.9772 - val_loss: 1.8518 - val_accuracy: 0.7727\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0594 - accuracy: 0.9837 - val_loss: 1.8310 - val_accuracy: 0.7468\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9788 - val_loss: 1.9823 - val_accuracy: 0.7403\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0999 - accuracy: 0.9674 - val_loss: 1.9159 - val_accuracy: 0.7208\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9886 - val_loss: 1.8143 - val_accuracy: 0.7468\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9870 - val_loss: 1.9276 - val_accuracy: 0.7532\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9902 - val_loss: 1.9169 - val_accuracy: 0.7727\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0792 - accuracy: 0.9756 - val_loss: 1.9376 - val_accuracy: 0.7468\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9902 - val_loss: 1.8512 - val_accuracy: 0.7597\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.9805 - val_loss: 1.9397 - val_accuracy: 0.7468\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.9837 - val_loss: 2.0849 - val_accuracy: 0.7338\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9788 - val_loss: 1.8552 - val_accuracy: 0.7662\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.9821 - val_loss: 1.9000 - val_accuracy: 0.7727\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9772 - val_loss: 1.9651 - val_accuracy: 0.7597\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.9853 - val_loss: 1.8996 - val_accuracy: 0.7597\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9837 - val_loss: 1.8627 - val_accuracy: 0.7468\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9837 - val_loss: 1.8674 - val_accuracy: 0.7597\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9772 - val_loss: 1.9463 - val_accuracy: 0.7143\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.9805 - val_loss: 2.0149 - val_accuracy: 0.7532\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ac91be3cd60>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Val_Accuracy = 75.32 and Model Tend to Overfit.\n",
        "## Lets Adddroput to tunning"
      ],
      "metadata": {
        "id": "5bdkPd3PxzDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Adding Dropout\n",
        "\n",
        "## Step 1: Building the Model\n",
        "\n",
        "def build_model_all_do(hp_all1):\n",
        "\n",
        "  counter = 0\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  for i in range(hp_all1.Int('Layers', 1,10)):\n",
        "\n",
        "    if counter==0 :\n",
        "\n",
        "      model.add(Dense(hp_all1.Int('Neuron'+str(i), 8,128,8),\n",
        "                      activation = hp_all1.Choice('Activation'+str(i), values = ['relu', 'sigmoid', 'tanh'])\n",
        "                      , input_dim =8))\n",
        "      model.add(Dropout(hp_all1.Choice('Dropout'+ str(i), values = [01.,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))\n",
        "\n",
        "    else :\n",
        "      model.add(Dense(hp_all1.Int('Neuron'+str(i), 8,128,8),\n",
        "                      activation = hp_all1.Choice('Activation'+str(i), values = ['relu', 'sigmoid', 'tanh'])))\n",
        "      model.add(Dropout(hp_all1.Choice('Dropout'+ str(i), values = [01.,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))\n",
        "\n",
        "    counter +=1\n",
        "\n",
        "    model.add(Dense(1, activation= 'sigmoid'))\n",
        "    model.compile( optimizer = hp_all1.Choice('Optimizer', values = ['rmsprop','adam','SGD', 'adadelta']),\n",
        "                  loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "9Jhc1um3VOaQ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2 : Creating Tunner Object\n",
        "\n",
        "tuner4  = kt.RandomSearch(build_model_all_do,\n",
        "                          objective = 'val_accuracy',\n",
        "                          max_trials = 5,\n",
        "                          directory = 'mydir',\n",
        "                          project_name = 'Tune_All_Including_DropOut')\n"
      ],
      "metadata": {
        "id": "PbMOqO-kWv2w"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Pass Data to the Tunner\n",
        "\n",
        "tuner4.search(x_train,y_train , epochs= 5, validation_data= (x_test,y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX-FOlrAXTLE",
        "outputId": "dbf6e2de-cad5-4d8a-92eb-de5f6bc67d02"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.7662337422370911\n",
            "\n",
            "Best val_accuracy So Far: 0.7792207598686218\n",
            "Total elapsed time: 00h 00m 12s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking Best Paramets\n",
        "\n",
        "tuner4.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO3wQMOwX9ju",
        "outputId": "dc0e36bc-c982-452c-ac77-11ff926b1ea2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Layers': 1,\n",
              " 'Neuron0': 112,\n",
              " 'Activation0': 'relu',\n",
              " 'Dropout0': 0.3,\n",
              " 'Optimizer': 'SGD'}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Building New MOdel with Tunner Inputs\n",
        "\n",
        "model= tuner4.get_best_models(num_models=1)[0]\n",
        "model.fit(x_train, y_train, epochs = 200 , initial_epoch=6,validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kesoGKZKYRE-",
        "outputId": "ee29aeee-6cdf-47ad-aa6b-a704d08b4ae2"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/200\n",
            "20/20 [==============================] - 1s 11ms/step - loss: 0.5667 - accuracy: 0.7296 - val_loss: 0.5437 - val_accuracy: 0.7922\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.7182 - val_loss: 0.5330 - val_accuracy: 0.7922\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7150 - val_loss: 0.5242 - val_accuracy: 0.7987\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7362 - val_loss: 0.5168 - val_accuracy: 0.7987\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7590 - val_loss: 0.5099 - val_accuracy: 0.8052\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7459 - val_loss: 0.5038 - val_accuracy: 0.7987\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5217 - accuracy: 0.7394 - val_loss: 0.4983 - val_accuracy: 0.7922\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7557 - val_loss: 0.4934 - val_accuracy: 0.7922\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7427 - val_loss: 0.4887 - val_accuracy: 0.7857\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7606 - val_loss: 0.4844 - val_accuracy: 0.7792\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7671 - val_loss: 0.4808 - val_accuracy: 0.7857\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7573 - val_loss: 0.4787 - val_accuracy: 0.7922\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7655 - val_loss: 0.4754 - val_accuracy: 0.7922\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7524 - val_loss: 0.4724 - val_accuracy: 0.7792\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7687 - val_loss: 0.4697 - val_accuracy: 0.7792\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7573 - val_loss: 0.4671 - val_accuracy: 0.7857\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7622 - val_loss: 0.4648 - val_accuracy: 0.7922\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7541 - val_loss: 0.4626 - val_accuracy: 0.7922\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4923 - accuracy: 0.7606 - val_loss: 0.4612 - val_accuracy: 0.7857\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7638 - val_loss: 0.4593 - val_accuracy: 0.7922\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7655 - val_loss: 0.4576 - val_accuracy: 0.7922\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4807 - accuracy: 0.7736 - val_loss: 0.4561 - val_accuracy: 0.7922\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7850 - val_loss: 0.4546 - val_accuracy: 0.7922\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7736 - val_loss: 0.4535 - val_accuracy: 0.7922\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7622 - val_loss: 0.4526 - val_accuracy: 0.7987\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7590 - val_loss: 0.4511 - val_accuracy: 0.7987\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7655 - val_loss: 0.4498 - val_accuracy: 0.7987\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7736 - val_loss: 0.4488 - val_accuracy: 0.7987\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.7671 - val_loss: 0.4480 - val_accuracy: 0.7987\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7720 - val_loss: 0.4468 - val_accuracy: 0.7922\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7573 - val_loss: 0.4467 - val_accuracy: 0.7922\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7622 - val_loss: 0.4457 - val_accuracy: 0.7922\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7687 - val_loss: 0.4451 - val_accuracy: 0.7987\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7736 - val_loss: 0.4438 - val_accuracy: 0.7987\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7736 - val_loss: 0.4431 - val_accuracy: 0.7922\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7720 - val_loss: 0.4422 - val_accuracy: 0.7987\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7622 - val_loss: 0.4413 - val_accuracy: 0.7987\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7704 - val_loss: 0.4407 - val_accuracy: 0.7987\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7671 - val_loss: 0.4398 - val_accuracy: 0.7987\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7557 - val_loss: 0.4391 - val_accuracy: 0.7922\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7785 - val_loss: 0.4384 - val_accuracy: 0.7922\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7785 - val_loss: 0.4381 - val_accuracy: 0.7922\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7752 - val_loss: 0.4377 - val_accuracy: 0.7987\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7785 - val_loss: 0.4371 - val_accuracy: 0.8052\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7785 - val_loss: 0.4367 - val_accuracy: 0.8052\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7834 - val_loss: 0.4361 - val_accuracy: 0.8052\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7834 - val_loss: 0.4359 - val_accuracy: 0.8052\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7769 - val_loss: 0.4353 - val_accuracy: 0.8052\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7671 - val_loss: 0.4346 - val_accuracy: 0.8052\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7671 - val_loss: 0.4345 - val_accuracy: 0.8052\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7704 - val_loss: 0.4341 - val_accuracy: 0.8052\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7736 - val_loss: 0.4337 - val_accuracy: 0.8052\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7736 - val_loss: 0.4335 - val_accuracy: 0.7987\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7818 - val_loss: 0.4329 - val_accuracy: 0.7987\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7557 - val_loss: 0.4327 - val_accuracy: 0.7987\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7801 - val_loss: 0.4323 - val_accuracy: 0.7987\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7687 - val_loss: 0.4317 - val_accuracy: 0.7922\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7818 - val_loss: 0.4312 - val_accuracy: 0.7922\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7834 - val_loss: 0.4310 - val_accuracy: 0.7922\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7785 - val_loss: 0.4306 - val_accuracy: 0.7922\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7687 - val_loss: 0.4302 - val_accuracy: 0.7922\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7736 - val_loss: 0.4298 - val_accuracy: 0.7857\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7687 - val_loss: 0.4297 - val_accuracy: 0.7922\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7752 - val_loss: 0.4295 - val_accuracy: 0.7922\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7818 - val_loss: 0.4292 - val_accuracy: 0.7922\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7752 - val_loss: 0.4290 - val_accuracy: 0.7922\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7769 - val_loss: 0.4288 - val_accuracy: 0.7922\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7736 - val_loss: 0.4284 - val_accuracy: 0.7922\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7866 - val_loss: 0.4284 - val_accuracy: 0.7922\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7899 - val_loss: 0.4282 - val_accuracy: 0.7922\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7948 - val_loss: 0.4285 - val_accuracy: 0.7922\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7736 - val_loss: 0.4285 - val_accuracy: 0.7922\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7736 - val_loss: 0.4284 - val_accuracy: 0.7922\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7834 - val_loss: 0.4280 - val_accuracy: 0.7922\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7704 - val_loss: 0.4276 - val_accuracy: 0.7922\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7785 - val_loss: 0.4275 - val_accuracy: 0.7922\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7785 - val_loss: 0.4271 - val_accuracy: 0.7922\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7752 - val_loss: 0.4271 - val_accuracy: 0.7922\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7834 - val_loss: 0.4269 - val_accuracy: 0.7857\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7720 - val_loss: 0.4271 - val_accuracy: 0.7922\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7915 - val_loss: 0.4270 - val_accuracy: 0.7922\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7818 - val_loss: 0.4267 - val_accuracy: 0.7922\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7752 - val_loss: 0.4266 - val_accuracy: 0.7922\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7752 - val_loss: 0.4264 - val_accuracy: 0.7922\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7736 - val_loss: 0.4263 - val_accuracy: 0.7922\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7638 - val_loss: 0.4261 - val_accuracy: 0.7922\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7883 - val_loss: 0.4262 - val_accuracy: 0.7857\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7850 - val_loss: 0.4264 - val_accuracy: 0.7857\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7834 - val_loss: 0.4262 - val_accuracy: 0.7922\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7899 - val_loss: 0.4261 - val_accuracy: 0.7922\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7704 - val_loss: 0.4259 - val_accuracy: 0.7922\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7932 - val_loss: 0.4261 - val_accuracy: 0.7922\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.7899 - val_loss: 0.4259 - val_accuracy: 0.7922\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7801 - val_loss: 0.4256 - val_accuracy: 0.7922\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7687 - val_loss: 0.4254 - val_accuracy: 0.7857\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7866 - val_loss: 0.4252 - val_accuracy: 0.7857\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7850 - val_loss: 0.4256 - val_accuracy: 0.7922\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7850 - val_loss: 0.4254 - val_accuracy: 0.7857\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7850 - val_loss: 0.4254 - val_accuracy: 0.7922\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7818 - val_loss: 0.4251 - val_accuracy: 0.7857\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7899 - val_loss: 0.4249 - val_accuracy: 0.7922\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7785 - val_loss: 0.4249 - val_accuracy: 0.7987\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7850 - val_loss: 0.4247 - val_accuracy: 0.7987\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7850 - val_loss: 0.4245 - val_accuracy: 0.7922\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7736 - val_loss: 0.4244 - val_accuracy: 0.7922\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4456 - accuracy: 0.7785 - val_loss: 0.4241 - val_accuracy: 0.7987\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7850 - val_loss: 0.4241 - val_accuracy: 0.7987\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.7915 - val_loss: 0.4241 - val_accuracy: 0.7987\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7834 - val_loss: 0.4241 - val_accuracy: 0.7922\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7752 - val_loss: 0.4242 - val_accuracy: 0.8052\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7818 - val_loss: 0.4244 - val_accuracy: 0.8052\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7818 - val_loss: 0.4245 - val_accuracy: 0.8052\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.7671 - val_loss: 0.4243 - val_accuracy: 0.8052\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4467 - accuracy: 0.7769 - val_loss: 0.4243 - val_accuracy: 0.8052\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7801 - val_loss: 0.4243 - val_accuracy: 0.7987\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7769 - val_loss: 0.4243 - val_accuracy: 0.7987\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.7899 - val_loss: 0.4240 - val_accuracy: 0.7987\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.7720 - val_loss: 0.4238 - val_accuracy: 0.7922\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7915 - val_loss: 0.4237 - val_accuracy: 0.7922\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7720 - val_loss: 0.4238 - val_accuracy: 0.7922\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7883 - val_loss: 0.4234 - val_accuracy: 0.7922\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7866 - val_loss: 0.4232 - val_accuracy: 0.7922\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7883 - val_loss: 0.4232 - val_accuracy: 0.7922\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7801 - val_loss: 0.4232 - val_accuracy: 0.7987\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7883 - val_loss: 0.4230 - val_accuracy: 0.7922\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7850 - val_loss: 0.4229 - val_accuracy: 0.7922\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7752 - val_loss: 0.4232 - val_accuracy: 0.7922\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7915 - val_loss: 0.4231 - val_accuracy: 0.7922\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7834 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7834 - val_loss: 0.4233 - val_accuracy: 0.7922\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7850 - val_loss: 0.4229 - val_accuracy: 0.7922\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7785 - val_loss: 0.4226 - val_accuracy: 0.7922\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7736 - val_loss: 0.4225 - val_accuracy: 0.7922\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7932 - val_loss: 0.4224 - val_accuracy: 0.7922\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7769 - val_loss: 0.4222 - val_accuracy: 0.7922\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7866 - val_loss: 0.4221 - val_accuracy: 0.7922\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7883 - val_loss: 0.4221 - val_accuracy: 0.7922\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7915 - val_loss: 0.4219 - val_accuracy: 0.7922\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7801 - val_loss: 0.4223 - val_accuracy: 0.7922\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7850 - val_loss: 0.4223 - val_accuracy: 0.7922\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7834 - val_loss: 0.4225 - val_accuracy: 0.7857\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7915 - val_loss: 0.4224 - val_accuracy: 0.7857\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7850 - val_loss: 0.4222 - val_accuracy: 0.7857\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7801 - val_loss: 0.4221 - val_accuracy: 0.7857\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7704 - val_loss: 0.4220 - val_accuracy: 0.7857\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7866 - val_loss: 0.4221 - val_accuracy: 0.7857\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7752 - val_loss: 0.4221 - val_accuracy: 0.7857\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7834 - val_loss: 0.4220 - val_accuracy: 0.7857\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7818 - val_loss: 0.4218 - val_accuracy: 0.7857\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7801 - val_loss: 0.4216 - val_accuracy: 0.7857\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7785 - val_loss: 0.4218 - val_accuracy: 0.7857\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7866 - val_loss: 0.4216 - val_accuracy: 0.7857\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7883 - val_loss: 0.4217 - val_accuracy: 0.7857\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7850 - val_loss: 0.4219 - val_accuracy: 0.7857\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7736 - val_loss: 0.4218 - val_accuracy: 0.7857\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7850 - val_loss: 0.4217 - val_accuracy: 0.7857\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7736 - val_loss: 0.4218 - val_accuracy: 0.7857\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7818 - val_loss: 0.4217 - val_accuracy: 0.7857\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7801 - val_loss: 0.4214 - val_accuracy: 0.7857\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7834 - val_loss: 0.4214 - val_accuracy: 0.7922\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7752 - val_loss: 0.4214 - val_accuracy: 0.7922\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7850 - val_loss: 0.4212 - val_accuracy: 0.7922\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7883 - val_loss: 0.4211 - val_accuracy: 0.7922\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7866 - val_loss: 0.4211 - val_accuracy: 0.7922\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7785 - val_loss: 0.4211 - val_accuracy: 0.7922\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7948 - val_loss: 0.4214 - val_accuracy: 0.7922\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7866 - val_loss: 0.4214 - val_accuracy: 0.7922\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.7818 - val_loss: 0.4214 - val_accuracy: 0.7922\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7834 - val_loss: 0.4213 - val_accuracy: 0.7922\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7883 - val_loss: 0.4211 - val_accuracy: 0.7922\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7801 - val_loss: 0.4213 - val_accuracy: 0.7922\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7932 - val_loss: 0.4211 - val_accuracy: 0.7922\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7932 - val_loss: 0.4209 - val_accuracy: 0.7922\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7883 - val_loss: 0.4210 - val_accuracy: 0.7922\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7752 - val_loss: 0.4209 - val_accuracy: 0.7922\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7818 - val_loss: 0.4209 - val_accuracy: 0.7922\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7850 - val_loss: 0.4209 - val_accuracy: 0.7922\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7883 - val_loss: 0.4208 - val_accuracy: 0.7922\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7915 - val_loss: 0.4206 - val_accuracy: 0.7922\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7883 - val_loss: 0.4204 - val_accuracy: 0.7922\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7964 - val_loss: 0.4203 - val_accuracy: 0.7922\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7785 - val_loss: 0.4205 - val_accuracy: 0.7922\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7704 - val_loss: 0.4205 - val_accuracy: 0.7922\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7834 - val_loss: 0.4204 - val_accuracy: 0.7922\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7866 - val_loss: 0.4205 - val_accuracy: 0.7922\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7801 - val_loss: 0.4209 - val_accuracy: 0.7922\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7850 - val_loss: 0.4212 - val_accuracy: 0.7922\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7850 - val_loss: 0.4212 - val_accuracy: 0.7922\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7883 - val_loss: 0.4211 - val_accuracy: 0.7922\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7818 - val_loss: 0.4209 - val_accuracy: 0.7922\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7932 - val_loss: 0.4211 - val_accuracy: 0.7857\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7769 - val_loss: 0.4210 - val_accuracy: 0.7922\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7785 - val_loss: 0.4210 - val_accuracy: 0.7922\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7948 - val_loss: 0.4209 - val_accuracy: 0.7922\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ac9297f5060>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Val_Accuracy = 79.22 and overfitting has been significatly reduced\n"
      ],
      "metadata": {
        "id": "aV9PHZ_IYye6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is How Hyperparamter Tunning Works"
      ],
      "metadata": {
        "id": "ofy0t4cP1MkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DUN__z8_1Pwd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}